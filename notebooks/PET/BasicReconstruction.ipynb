{
 "metadata": {
  "name": "",
  "signature": "sha256:08b33f06d93c457d1fb1c0873fd3c2189c44171da7b6f9658de3e6eec028c895"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "#%% Initial imports etc\n",
      "import numpy\n",
      "from numpy.linalg import norm\n",
      "%matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "import os\n",
      "import sys\n",
      "import shutil\n",
      "# plotting settings\n",
      "plt.ion() # interactive 'on' such that plots appear during loops\n",
      "#%% Use the 'pet' prefix for all SIRF functions\n",
      "# This is done here to explicitly differentiate between SIRF pet functions and \n",
      "# anything else.\n",
      "import pSTIR as pet\n",
      "\n",
      "#%% Go to directory with input files\n",
      "# Adapt this path to your situation (or start everything in the relevant directory)\n",
      "os.chdir(pet.petmr_data_path('pet'))\n",
      "#%% Copy files to a working folder and change directory to where these files are.\n",
      "# We do this to avoid cluttering your SIRF files. This way, you can delete \n",
      "# working_folder and start from scratch.\n",
      "shutil.rmtree('working_folder/brain',True)\n",
      "shutil.copytree('brain','working_folder/brain')\n",
      "os.chdir('working_folder/brain')\n",
      "#%% Read in images\n",
      "# Here we will read some images provided with the demo using the ImageData class.\n",
      "# These are in Interfile format. Check the main SIRF doc.\n",
      "image = pet.ImageData('emission.hv');\n",
      "image_array=image.as_array();\n",
      "image_array*=0.01;\n",
      "# Stick this new data into the original image object.\n",
      "# (This will not modify the file content, only the variable in memory.)\n",
      "image.fill(image_array);\n",
      "\n",
      "mu_map = pet.ImageData('attenuation.hv');\n",
      "#%% Specify sinogram dimensions\n",
      "# We need to say what scanner to use, what dimensions etc.\n",
      "# You do this by using existing PET data as a 'template'. \n",
      "# We read a file supplied with the demo as an AcquisitionData object\n",
      "templ = pet.AcquisitionData('template_sinogram.hs');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% just check if you ran the previous demo\n",
      "if 'image' in globals():\n",
      "    print('Ok, we can proceed')\n",
      "else:\n",
      "    print('This script assumes you have run the display_and_projection.py demo first!')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ok, we can proceed\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Import some extra functions\n",
      "from pUtilities import show_2D_array, show_3D_array\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Do a forward projection of our image\n",
      "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
      "am.set_up(templ,image); \n",
      "acquired_data=am.forward(image)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% create objective function\n",
      "obj_fun = pet.make_Poisson_loglikelihood(acquired_data)\n",
      "obj_fun.set_acquisition_model(am)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% create OSMAPOSL reconstructor\n",
      "# This implements the Ordered Subsets Maximum A-Posteriori One Step Late\n",
      "# Since we are not using a penalty, or prior in this example, it\n",
      "# defaults to using MLEM, but we will modify it to OSEM\n",
      "recon = pet.OSMAPOSLReconstructor()\n",
      "recon.set_objective_function(obj_fun)\n",
      "recon.set_num_subsets(4)\n",
      "recon.set_num_subiterations(5)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% reconstruct the image \n",
      "# First create a new image to use for the reconstruction\n",
      "# We will just use the original as a 'template' to have the same voxel sizes etc\n",
      "reconstructed_image=image.clone()\n",
      "# Set its values to 1 to create a uniform image\n",
      "reconstructed_image.fill(1)\n",
      "# set up the reconstructor\n",
      "recon.set_up(reconstructed_image)\n",
      "# do actual recon\n",
      "recon.reconstruct(reconstructed_image)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% display of image\n",
      "reconstructed_array=reconstructed_image.as_array()\n",
      "slice=reconstructed_array.shape[0]/3;\n",
      "show_2D_array('reconstructed image after 5 iterations',reconstructed_array[slice,:,:,]);\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Close Figure 1 window to continue...\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% do a another set of iterations\n",
      "recon.reconstruct(reconstructed_image)\n",
      "reconstructed_array=reconstructed_image.as_array()\n",
      "show_2D_array('reconstructed image after 10 iterations',reconstructed_array[slice,:,:,]);\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Close Figure 2 window to continue...\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% We now add a multiplicative term to the acquisition model\n",
      "# In PET, detector-pairs have different efficiencies. We want to include\n",
      "# this in our 'forward' model such that the reconstruction can\n",
      "# take this into account.\n",
      "#\n",
      "# The way to do this in SIRF is to include 'bin efficiencies' in the model,\n",
      "# i.e. one multiplicative factor for each bin in the data.\n",
      "#\n",
      "# You would normally derive these efficiencies from a \"normalisation\" scan.\n",
      "# Here we will simply set the efficiencies for some 'views' to zero.\n",
      "# This is actually physically impossible for PET (although ok for SPECT),\n",
      "# but this is only a demo!\n",
      "\n",
      "# first create a copy of the data such that we have an object of the appropriate size\n",
      "bin_efficiencies = acquired_data.clone()\n",
      "# set all values to 1\n",
      "bin_efficiencies.fill(1.)\n",
      "# set a portion of bin efficiencies to zero;\n",
      "bin_efficiencies_array = bin_efficiencies.as_array()\n",
      "bin_efficiencies_array[:,5:20,:] = 0\n",
      "bin_efficiencies.fill(bin_efficiencies_array)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "<sirf.STIR.AcquisitionData at 0x7efe7a9b4c50>"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Create a new acquisition model\n",
      "am2 = pet.AcquisitionModelUsingRayTracingMatrix()\n",
      "am2.set_num_tangential_LORs(5);\n",
      "am2.set_up(templ,image); \n",
      "# now include the bin efficiencies in our acquisition model\n",
      "#am2.set_bin_efficiency(bin_efficiencies)\n",
      "asm = pet.AcquisitionSensitivityModel(bin_efficiencies)\n",
      "am2.set_acquisition_sensitivity(asm)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% forward project the image again with this acquisition model and display\n",
      "\n",
      "\n",
      "acquired_data = am2.forward(image)\n",
      "acquisition_array = acquired_data.as_array()\n",
      "show_3D_array(acquisition_array);\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "File: /home/sirfuser/devel/install/python/sirf/STIR.py\n",
        "Line: 1099\n",
        "check_status found the following message sent from the engine:\n"
       ]
      },
      {
       "ename": "error",
       "evalue": "??? \"'BinNormalisation method called without calling set_up first.' exception caught at line 425 of /home/sirfuser/devel/buildVM/sources/SIRF/src/xSTIR/cSTIR/cstir.cpp\\nthe reconstruction engine output may provide more information\"",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-33-1177b5768a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macquired_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mam2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0macquisition_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquired_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshow_3D_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sirfuser/devel/install/python/sirf/STIR.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAcquisitionData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpystir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcSTIR_acquisitionModelFwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0mcheck_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/sirfuser/devel/install/python/sirf/Utilities.pyc\u001b[0m in \u001b[0;36mcheck_status\u001b[0;34m(handle, stack)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;34m'the reconstruction engine output may provide more information'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrorMsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31merror\u001b[0m: ??? \"'BinNormalisation method called without calling set_up first.' exception caught at line 425 of /home/sirfuser/devel/buildVM/sources/SIRF/src/xSTIR/cSTIR/cstir.cpp\\nthe reconstruction engine output may provide more information\""
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Let us reconstruct this data with the original acquisition model (without bin efficiencies)\n",
      "obj_fun.set_acquisition_data(acquired_data)\n",
      "obj_fun.set_acquisition_model(am)\n",
      "reconstructed_image.fill(1)\n",
      "recon.set_up(reconstructed_image)\n",
      "recon.set_num_subiterations(10)\n",
      "recon.reconstruct(reconstructed_image)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% display\n",
      "# we fix the max for the colour scale related to the true max\n",
      "cmax = image.as_array().max()*1.2;\n",
      "reconstructed_array=reconstructed_image.as_array()\n",
      "plt.figure()\n",
      "imshow(reconstructed_array[slice,:,:,], [0,cmax],'reconstructed image with original acquisition model');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'imshow' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-19-d267198dab15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreconstructed_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreconstructed_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'reconstructed image with original acquisition model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'imshow' is not defined"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Now we use the correct acquisition model\n",
      "obj_fun.set_acquisition_model(am2)\n",
      "reconstructed_image.fill(1)\n",
      "recon.set_up(reconstructed_image)\n",
      "recon.reconstruct(reconstructed_image)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% display\n",
      "reconstructed_array=reconstructed_image.as_array()\n",
      "plt.figure()\n",
      "imshow(reconstructed_array[slice,:,:,], [0,cmax],'reconstructed image with correct acquisition model');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}