{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "###\n",
    "# Demonstration of MR reconstruction with CCP PET-MR Software\n",
    "#\n",
    "# This demonstration shows how to hande undersampled data\n",
    "# and how to write a simple iterative reconstruction algorithm with\n",
    "# the acquisition model.\n",
    "#\n",
    "# This demo is a 'script', i.e. intended to be run step by step in a\n",
    "# Python IDE such as spyder. It is organised in 'cells'. spyder displays these\n",
    "# cells nicely and allows you to run each cell on its own.\n",
    "#\n",
    "# First version: 27th of March 2019\n",
    "# Author: Johannes Mayer\n",
    "#\n",
    "\n",
    "## CCP PETMR Synergistic Image Reconstruction Framework (SIRF).\n",
    "## Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.\n",
    "## Copyright 2015 - 2017 University College London.\n",
    "## Copyright 2015 - 2017 Physikalisch-Technische Bundesanstalt.\n",
    "##\n",
    "## This is software developed for the Collaborative Computational\n",
    "## Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "## (http://www.ccppetmr.ac.uk/).\n",
    "##\n",
    "## Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "##   you may not use this file except in compliance with the License.\n",
    "##   You may obtain a copy of the License at\n",
    "##       http://www.apache.org/licenses/LICENSE-2.0\n",
    "##   Unless required by applicable law or agreed to in writing, software\n",
    "##   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "##   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "##   See the License for the specific language governing permissions and\n",
    "##   limitations under the License.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "__version__ = '0.1.0'\n",
    "\n",
    "# import engine module\n",
    "import pGadgetron as pMR\n",
    "\n",
    "# import further modules\n",
    "import os, numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% GO TO MR FOLDER\n",
    "os.chdir(pMR.petmr_data_path('mr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to get warmed up again:\n",
    "Since we deal with undersampled data in this last section, we need to compare it to a reference.\n",
    "So we need to reconstruct the fully sampled dataset we encountered before.\n",
    "\n",
    "This is an ideal opprotunity to test what we learned and employ the `pMR.FullSampledReconstructor` class from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Task: Fully sampled reconstruction\n",
    "\n",
    "__Hint:__ As always: the `Tab` key is your friend and autosuggestion tool!\n",
    "\n",
    "__Please write code that does the following:__\n",
    "- create a variable called `full_acq_data` of type `pMR.AcquisitionData` from the file simulated_MR_2D_cartesian.h5\n",
    "- create a variable called `pp_full_acq_data` and assign it the preprocessed data by calling the function `pMR.preprocess_acquisition_data` on our variable `full_acq_data`\n",
    "- create a variable called `recon` of type `pMR.FullySampledReconstructor()`\n",
    "- call the `set_input` method of `recon` on `pp_full_acq_data` to assign our fully sampled dataset to our reconstructor\n",
    "- call the `process()` method of `recon` without arguments (but don't forget the brackets!)\n",
    "- create a variable called `fs_image` and assign it the output of the `get_output` method of `recon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't look at the solution before you tried! \n",
    "Cells to run:\n",
    "- Skip `#Solution Cell` if you want to see if your code works and run #Validation Cell instead.\n",
    "- If it fails, run `#Solution Cell` instead and then `#Validation Cell` afterwards. Then you are up to date again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Cell\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_acq_data = pMR.AcquisitionData('simulated_MR_2D_cartesian.h5')\n",
    "pp_full_acq_data = pMR.preprocess_acquisition_data( full_acq_data )\n",
    "\n",
    "recon = pMR.FullySampledReconstructor()\n",
    "recon.set_input( pp_full_acq_data )\n",
    "recon.process()\n",
    "fs_image = recon.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VALIDATION CELL\n",
    "fs_image_array = fs_image.as_array()\n",
    "fs_image_array = fs_image_array/fs_image_array.max()\n",
    "plt.close()\n",
    "fig = plt.figure(1)\n",
    "plt.set_cmap('gray')\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow( abs(fs_image_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('Fully sampled reconstruction')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our first function: the FFT\n",
    "def our_fft( k_array ):\n",
    "    # format output\n",
    "    image_array = numpy.zeros(k_array.shape, numpy.complex128)\n",
    "    \n",
    "    # perform FFT for each channel\n",
    "    for c in range(num_channels):\n",
    "        image_array[:,c,:] = numpy.fft.fftshift( numpy.fft.ifft2( numpy.fft.ifftshift(k_array[:,c,:])))\n",
    "    \n",
    "    image_array = image_array/image_array.max()  \n",
    "    \n",
    "    # combine the channels using SOS\n",
    "    image_array = numpy.sqrt( numpy.sum( numpy.square(image_array),1))\n",
    "    image_array = image_array/image_array.max()  \n",
    "\n",
    "    return image_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING AND PREPROCESSING DATA FOR THIS SET\n",
    "acq_data = pMR.AcquisitionData('simulated_MR_2D_cartesian_Grappa2.h5')\n",
    "preprocessed_data = pMR.preprocess_acquisition_data(acq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the data we loaded sorted? False\n",
      "Is the data we loaded undersampled? 1\n"
     ]
    }
   ],
   "source": [
    "# LET'S GET SOME INFORMATION FROM THE DATA\n",
    "print('Is the data we loaded sorted? %s' % preprocessed_data.is_sorted())\n",
    "print('Is the data we loaded undersampled? %s' % preprocessed_data.is_undersampled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the data we loaded sorted? True\n"
     ]
    }
   ],
   "source": [
    "# OK SO LET'S SORT IT THEN\n",
    "preprocessed_data.sort()\n",
    "print('Is the data we loaded sorted? %s' % preprocessed_data.is_sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of k-space 160x8x256\n"
     ]
    }
   ],
   "source": [
    "#%% RETRIEVE K-SPACE DATA\n",
    "k_array = preprocessed_data.as_array()\n",
    "print('Size of k-space %dx%dx%d' % k_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of k-space 160x8x256\n"
     ]
    }
   ],
   "source": [
    "#%% SELECT VIEW DATA FROM DIFFERENT COILS\n",
    "print('Size of k-space %dx%dx%d' % k_array.shape)\n",
    "\n",
    "num_channels = k_array.shape[1]\n",
    "\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure(1)\n",
    "plt.set_cmap('gray')\n",
    "for c in range(num_channels):\n",
    "    ax = fig.add_subplot(2,4,c+1)\n",
    "    ax.imshow(abs(k_array[:,c,:]), vmin=0, vmax=1)\n",
    "    ax.set_title('Coil '+str(c+1))\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty similar to what we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we make a FFT of the data we looked at and compare it to our fully sampled image\n",
    "image_array_sos = our_fft( k_array )\n",
    "image_array_sos = image_array_sos/image_array_sos.max()\n",
    "\n",
    "fig = plt.figure(3)\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(abs(image_array_sos), vmin=0, vmax=1)\n",
    "ax.set_title('Undersampled')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(abs(fs_image_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('Fully Sampled')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "Please answer the following question for yourself:\n",
    "- What differences appear between the two reconstructions?\n",
    "- What artifacts appear in the Undersampled reconstruction?\n",
    "- Why is the undersampled reconstruction clinched, but contains the whole image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW LET's PROCEED AND GET SOME INFO IN THIS DATASET\n",
    "which_ro = preprocessed_data.get_info('kspace_encode_step_1')\n",
    "sampling_mask = numpy.zeros([256,256])\n",
    "\n",
    "for ro in which_ro:\n",
    "    sampling_mask[ro,:] = 1\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure(1)\n",
    "plt.set_cmap('gray')\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow( sampling_mask, vmin=0, vmax=1)\n",
    "ax.set_title('Sampling pattern of a GRAPPA acquisition')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK INTERMEZZO: WE DEFINE A FUCTION:\n",
    "def fft_and_sos( k_array ):\n",
    "    image_array = numpy.zeros(k_array.shape, numpy.complex128)\n",
    "    for c in range(num_channels):\n",
    "        image_array[:,c,:] = numpy.fft.fftshift( numpy.fft.ifft2( numpy.fft.ifftshift(k_array[:,c,:])))\n",
    "    image_array = image_array/image_array.max()    \n",
    "    \n",
    "    image_array_sos = numpy.sqrt( numpy.sum( numpy.square(image_array),1))\n",
    "    image_array_sos = image_array_sos/image_array_sos.max()\n",
    "    \n",
    "    return image_array_sos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workaround: 'zero-fill' the k-space data\n",
    "Since the shape of the data seems to be the problem, let's just change that shape into the one we want.\n",
    "\n",
    "But can we just add datapoints? This will corrupt the data!\n",
    "\n",
    "Actually, a Fourier transform is just a sum weighted by a phase. \n",
    "\n",
    "So it does not mind if we add zeros to it!\n",
    "\n",
    "This means we make a larger array, add our data in the correct spots, and the gaps we fill with zeros. The correct spots are given by our sampling mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_shape = [sampling_mask.shape[0], num_channels, sampling_mask.shape[1]]\n",
    "zf_k_array = numpy.zeros(k_shape, numpy.complex128)\n",
    "\n",
    "for i in range(k_array.shape[0]):\n",
    "    zf_k_array[which_ro[i],:,:] = k_array[i,:,:]\n",
    "\n",
    "\n",
    "zf_recon = fft_and_sos( zf_k_array)\n",
    "\n",
    "fig = plt.figure(4)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(zf_recon), vmin=0, vmax=1)\n",
    "ax.set_title('Zero-filled iFFT')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHICH COILMAPS DO WE GET FROM THIS DATASET?\n",
    "csm = pMR.CoilSensitivityData()\n",
    "csm.smoothness = 40\n",
    "csm.calculate(preprocessed_data)\n",
    "csm_array = numpy.squeeze(csm.as_array(0))\n",
    "\n",
    "csm_array = csm_array.transpose([1,0,2])\n",
    "\n",
    "fig = plt.figure(4)\n",
    "plt.set_cmap('jet')\n",
    "for c in range(csm_array.shape[1]):\n",
    "    ax = fig.add_subplot(2,4,c+1)\n",
    "    ax.imshow(abs(csm_array[:,c,:]))\n",
    "    ax.set_title('Coil '+str(c+1))\n",
    "    ax.axis('off')\n",
    "plt.set_cmap('gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "Why is it not important in estimating coilmaps, that\n",
    "- we have only the center of the k-space sampled?\n",
    "- there are artifacts in the reconstruction? Why are they not in the coilmaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW DO A GRAPPA RECONSTRUCTION\n",
    "\n",
    "recon = pMR.CartesianGRAPPAReconstructor()\n",
    "recon.set_input(preprocessed_data)\n",
    "recon.compute_gfactors(False)\n",
    "print('---\\n reconstructing...')\n",
    "recon.process()\n",
    "# for undersampled acquisition data GRAPPA computes Gfactor images\n",
    "# in addition to reconstructed ones\n",
    "grappa_images = recon.get_output()\n",
    "grappa_images_array = grappa_images.as_array()\n",
    "grappa_images_array = grappa_images_array/grappa_images_array.max()\n",
    "\n",
    "fig = plt.figure(4)\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(abs(grappa_images_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('GRAPPA Reconstruction')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(abs(zf_recon), vmin=0, vmax=1)\n",
    "ax.set_title('ZF iFFT Reconstruction ')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Well, that was very little code to perform a difficult task!\n",
    "\n",
    "In what respect did a GRAPPA reconstruction:\n",
    "\n",
    " * improve the resulting image?\n",
    " * deterioate the resulting image?\n",
    " * why is there more noise in the GRAPPA reconstruction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREAT! Now we want to develop our own algorithm and be better than the GRAPPA reconstruction!\n",
    "## Urgh, let's rather not because we are so annoyed at how much code we have to write all the time!\n",
    "### Enter: AcquisitionModel\n",
    "\n",
    "We want to capture our entire imaging and reconstruction process in one single object and don't care about data structure. Also we don't want to have to sum over coil channels all the time and take care of zero filling, this is just too much work!  \n",
    "\n",
    "In SIRF there exists something called AcquisitionModel, in the literature also referenced as and Encoding operator $E$, E for encoding.\n",
    "\n",
    "For an image $x$, we want to be able to go __forward__ into k-space\n",
    "$$ E: x \\rightarrow y $$\n",
    "implicitly performing multiplication of the image with the coil sensitivities $C_c$ for each channel $c$ and performing an FFT:\n",
    "\n",
    "$$\n",
    "E x = y_c = \\mathcal{F}( C_c \\cdot x) \n",
    "$$\n",
    "\n",
    "For given k-space data, we want to __backward__ into image space, doing the zero-filling, inverse FFT, and coil combination as one single operation:\n",
    "$$ E^H: y \\rightarrow x $$\n",
    ", implicitly performing everything:  \n",
    "$$\n",
    "E^H y = x =  \\frac{\\sum_c C_c^*\\mathcal{F}^{-1}(y) }{\\sum_c C_c^*C_c}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE GENERATE THE E OPERATOR FROM ABOVE AND ASSIGN OUR COIL SENSITIVITIES\n",
    "E = pMR.AcquisitionModel(preprocessed_data, grappa_images)\n",
    "E.set_coil_sensitivity_maps(csm)\n",
    "\n",
    "# Now we can hop back from k-space to image space in just one line:\n",
    "ifft_image = E.backward( preprocessed_data )\n",
    "ifft_image_array = ifft_image.as_array()\n",
    "\n",
    "# Suddenly implementing a new algorithm seems feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEFORE YOU RUN THE NEXT CELL AND LOOK AT THE PLOT:\n",
    "In the next plot the image stored in `ifft_image` will be shown, i.e. $x = E^H y$.  \n",
    "Based on the discussion what the AcquisitionModel E does, what do you expect the reconstruction to look like?\n",
    "- Is it clinched or is it the correct size?\n",
    "- Does it contain artifacts? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.set_cmap('gray')\n",
    "fig = plt.figure(5)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(ifft_image_array[0,:,:]))\n",
    "ax.set_title('Simple Inverse Fourier Transform')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Gradient SENSE\n",
    "## Iterative Parallel Imaging Reconstruction\n",
    "\n",
    "In order to reconstruct images we want to achieve the following equality:\n",
    "$$ E \\tilde{x} = y $$, or equivalently\n",
    "$$ E^H E x = E^H y$$ \n",
    "where $E$ is the encoding operator $\\tilde{x}$ is the true image object and $y$ is the MR raw data. \n",
    "The task of image reconstruction boils down to optimizing the following function:\n",
    "$$ \\mathcal{C}(x) = \\frac{1}{2} \\bigl{|} \\bigl{|}  E x - y \\bigr{|} \\bigr{|}_2  \\\\\n",
    "\\tilde{x} = \\min_x \\mathcal{C}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to implement Conjugate Gradient Descent SENSE\n",
    "\n",
    "For that we need to write a bit of code:\n",
    "- We already have this encoding operator `E` defined.\n",
    "- Now we need to use it to iteratively optimize our cost function with a conjugate gradient descent optimization.\n",
    "\n",
    "To this end we can study the corresponding [Wikipedia Article](https://en.wikipedia.org/wiki/Conjugate_gradient_method#Description_of_the_problem_addressed_by_conjugate_gradients).\n",
    "\n",
    "This looks like our thang! We don't care too much about maths, but we want the [algorithm](https://en.wikipedia.org/wiki/Conjugate_gradient_method#The_resulting_algorithm).\n",
    "\n",
    "\n",
    "They want to compute x in $Ax = b$, we want to compute x in $E^H E x = E^H y$.  \n",
    "This means we need to translate what it says on Wikipedia:\n",
    "- $A$ = $E^HE$\n",
    "- $b$ = $E y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming task\n",
    "Please write code executing the following task:\n",
    "- define a fuction named `EhE`\n",
    "- it should have one single argument `image`\n",
    "- it should return $E^H( E (image))$  \n",
    "\n",
    "__Hint 1:__ We defined `E` already. Use it's methods `forward` and `backward`. `forward` goes from image space to k-space and `backward` the other way round.  \n",
    "__Hint 2:__ Short reminder on the syntax. The function should look like: \n",
    "```\n",
    "def function_name( arugment_name):\n",
    "    object = code_that_does_something_with ( argument_name )\n",
    "    return object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (this is as much space as you need!)\n",
    "# make sure the name of your function is EhE \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't look at the solution before you tried! \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We define a function to save some work\n",
    "def EhE( image ):\n",
    "    return E.backward( E.forward(image) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our images should be the same shape as the GRAPPA outout\n",
    "recon_img =  grappa_images \n",
    "\n",
    "# but we want to start from zero\n",
    "zero_array = recon_img.as_array()\n",
    "zero_array.fill(0)\n",
    "recon_img.fill(zero_array)\n",
    "\n",
    "# now name the variables the same as in the wikipedia article:\n",
    "y = preprocessed_data\n",
    "x = recon_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming task\n",
    "Please write code executing the following task:\n",
    "- Initialize a variable `r` with `r` = $b - Ax$ (`r` stands for residual) If you forgot what $b$ and $A$ were in our context scroll back up!\n",
    "- Print the type of `r` using Pythons `type()` function. What type do you expect? Is it an image, or is it acquisition data?\n",
    "- Run your cell once, to get the output of the print statement.\n",
    "- Afterwards, initialize a variable named `rr` with `rr` = $r^\\dagger r$. (`rr` stands for r times r)  \n",
    "__Hint__: No need to access any numpy arrays! Objects of type `sirf.Gadgetron.ImageData` have the method called ` norm()` giving you the square root of the quanitity we are looking for. `rr` is the value of the cost funciton by the way.\n",
    "- Initialize a variable `rr0` with the value of `rr` to store the starting norm of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE IN THIS CELL\n",
    "## Please make sure to name the variables correctly\n",
    "\n",
    "r = E.backward( y ) - EhE(x)\n",
    "print( type( r ) )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Don't look at the solution before you tried! #############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# this is our first residual\n",
    "r = E.backward( y ) - EhE(x)\n",
    "\n",
    "# print the type\n",
    "print('The type of r is: ' + str( type(r) ) ) \n",
    "\n",
    "# this is our cost function at the start\n",
    "rr = r.norm() ** 2\n",
    "rr0 = rr\n",
    "\n",
    "# intialize p\n",
    "p = r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we write down the algorithm\n",
    "\n",
    "# how many iterative steps do we want\n",
    "# how low should the cost be\n",
    "num_iter = 10\n",
    "accuracy = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cost for k = 0: '  + str( rr/ rr0) )\n",
    "for k in range(num_iter):\n",
    "    \n",
    "    Ap = EhE( p )\n",
    "       \n",
    "    alpha = rr / numpy.sum( (numpy.conj(p.as_array())) * Ap.as_array() ) \n",
    "    \n",
    "    x = x + alpha * p\n",
    "    r = r - alpha * Ap\n",
    "    \n",
    "    beta  = r.norm()**2 / rr\n",
    "    rr = r.norm()**2\n",
    "    \n",
    "    p = r + beta * p\n",
    "    \n",
    "    print('Cost for k = ' +str(k+1) + ': ' + str( rr/ rr0) )\n",
    "    if( rr/rr0 < accuracy ):\n",
    "        print( 'We achieved our desired accuracy. Stopping iterative reconstruction' )\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_arr = x.as_array()\n",
    "print(recon_arr.shape)\n",
    "\n",
    "\n",
    "plt.set_cmap('gray')\n",
    "fig = plt.figure(5)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(recon_arr[0,:,:]))\n",
    "ax.set_title('SENSE RECONSTRUCTION')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(5)\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(grappa_images_array[0,:,:]))\n",
    "ax.set_title('GRAPPA RECONSTRUCTION')\n",
    "ax.axis('off')\n",
    "\n",
    "fig = plt.figure(6)\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(recon_arr[0,:,:]))\n",
    "ax.set_title('SENSE RECONSTRUCTION')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_SENSE( image, kdata, E ):\n",
    "    rr_1 = rr\n",
    "    rr = (r.norm()) ** 2\n",
    "    \n",
    "    if i==0:\n",
    "        p = r;\n",
    "    else:\n",
    "        beta = rr/rr_1\n",
    "        p = r + beta*p\n",
    "        \n",
    "        \n",
    "    p_1 = p\n",
    "    \n",
    "    q = E.backward( E.forward( p_1 ))\n",
    "    \n",
    "    p_flat = p.as_array().flatten()\n",
    "    q_flat = q.as_array().flatten()\n",
    "    \n",
    "       \n",
    "    alpha = rr/numpy.sum( numpy.conj(p_flat) * q_flat ,0)\n",
    "    print(alpha)\n",
    "    recon_img = recon_img + alpha * p\n",
    "    r = r - alpha * q\n",
    "    print( rr/ rr_0 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
