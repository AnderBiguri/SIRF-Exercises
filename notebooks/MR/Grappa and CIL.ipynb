{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCPi CIL and SIRF\n",
    "\n",
    "* CIL is an heterogeneous collection of software codes for Computed Tomography\n",
    "* Beam Hardening\n",
    "* CT iterative reconstruction algorithms in C++\n",
    "* Segmentation\n",
    "* Digital Volume correlation (for strain)\n",
    "* Visualisation (3D Viewer)\n",
    "\n",
    "## Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GRAPPA reconstruction with an iterative algorithm from CIL: illustrates\n",
    "the use of AcquisitionModel in CIL optimisation \n",
    "\n",
    "Usage:\n",
    "  grappa_and_cil.py [--help | options]\n",
    "\n",
    "Options:\n",
    "  -f <file>, --file=<file>    raw data file\n",
    "                              [default: simulated_MR_2D_cartesian_Grappa2.h5]\n",
    "  -p <path>, --path=<path>    path to data files, defaults to data/examples/MR\n",
    "                              subfolder of SIRF root folder\n",
    "'''\n",
    "\n",
    "## CCP PETMR Synergistic Image Reconstruction Framework (SIRF)\n",
    "## Copyright 2015 - 2019 Rutherford Appleton Laboratory STFC.\n",
    "## Copyright 2015 - 2019 University College London.\n",
    "##\n",
    "## This is software developed for the Collaborative Computational\n",
    "## Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "## (http://www.ccppetmr.ac.uk/).\n",
    "##\n",
    "## Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "##   you may not use this file except in compliance with the License.\n",
    "##   You may obtain a copy of the License at\n",
    "##       http://www.apache.org/licenses/LICENSE-2.0\n",
    "##   Unless required by applicable law or agreed to in writing, software\n",
    "##   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "##   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "##   See the License for the specific language governing permissions and\n",
    "##   limitations under the License.\n",
    "\n",
    "\n",
    "import sirf\n",
    "from sirf.Utilities import existing_filepath\n",
    "from sirf.Utilities import error\n",
    "from sirf.Utilities import show_3D_array\n",
    "from sirf.Gadgetron import petmr_data_path\n",
    "from sirf.Gadgetron import AcquisitionData, ImageData\n",
    "from sirf.Gadgetron import AcquisitionModel\n",
    "from sirf.Gadgetron import AcquisitionDataProcessor\n",
    "from sirf.Gadgetron import CartesianGRAPPAReconstructor\n",
    "from sirf.Gadgetron import CoilSensitivityData\n",
    "\n",
    "\n",
    "from ccpi.optimisation.funcs import Norm2sq\n",
    "from ccpi.optimisation.funcs import ZeroFun\n",
    "#from ccpi.optimisation.algs import FISTA, FBPD, CGLS\n",
    "#from ccpi.optimisation.ops import PowerMethodNonsquare\n",
    "from ccpi.plugins.regularisers import FGP_TV#, TGV, LLT_ROF, Diff4th\n",
    "from ccpi.framework import DataContainer as cilDataContainer\n",
    "\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "\n",
    "class Algorithm(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.iteration = 0\n",
    "        self.stop_cryterion = 'max_iter'\n",
    "        self.__max_iteration = 0\n",
    "        self.__loss = []\n",
    "        self.memopt = False\n",
    "        self.timing = []\n",
    "    def set_up(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    def update(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def should_stop(self):\n",
    "        '''stopping cryterion'''\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def next(self):\n",
    "        '''python2 backwards compatibility'''\n",
    "        return self.__next__()\n",
    "    def __next__(self):\n",
    "        if self.should_stop():\n",
    "            raise StopIteration()\n",
    "        else:\n",
    "            time0 = time.time()\n",
    "            self.update()\n",
    "            self.timing.append( time.time() - time0 )\n",
    "            self.update_objective()\n",
    "            self.iteration += 1\n",
    "    def get_output(self):\n",
    "        '''Returns the solution found'''\n",
    "        return self.x\n",
    "    def get_current_loss(self):\n",
    "        '''Returns the current value of the loss function'''\n",
    "        return self.__loss[-1]\n",
    "    def update_objective(self):\n",
    "        raise NotImplementedError()\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.__loss\n",
    "    @property\n",
    "    def max_iteration(self):\n",
    "        return self.__max_iteration\n",
    "    @max_iteration.setter\n",
    "    def max_iteration(self, value):\n",
    "        assert isinstance(value, int)\n",
    "        self.__max_iteration = value\n",
    "    \n",
    "class GradientDescent(Algorithm):\n",
    "    '''Implementation of a simple Gradient Descent algorithm\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        '''initialisation can be done at creation time if all \n",
    "        proper variables are passed or later with set_up'''\n",
    "        super(GradientDescent, self).__init__()\n",
    "        self.x = None\n",
    "        self.rate = 0\n",
    "        self.objective_function = None\n",
    "        self.regulariser = None\n",
    "        args = ['x_init', 'objective_function', 'rate']\n",
    "        for k,v in kwargs.items():\n",
    "            if k in args:\n",
    "                args.pop(args.index(k))\n",
    "        if len(args) == 0:\n",
    "            return self.set_up(x_init=kwargs['x_init'],\n",
    "                               objective_function=kwargs['objective_function'],\n",
    "                               rate=kwargs['rate'])\n",
    "    \n",
    "    def should_stop(self):\n",
    "        '''stopping cryterion, currently only based on number of iterations'''\n",
    "        return self.iteration >= self.max_iteration\n",
    "    \n",
    "    def set_up(self, x_init, objective_function, rate):\n",
    "        '''initialisation of the algorithm'''\n",
    "        self.x = x_init.copy()\n",
    "        if self.memopt:\n",
    "            self.x_update = x_init.copy()\n",
    "        self.objective_function = objective_function\n",
    "        self.rate = rate\n",
    "        self.loss.append(objective_function(x_init))\n",
    "        \n",
    "    def update(self):\n",
    "        '''Single iteration'''\n",
    "        if self.memopt:\n",
    "            self.objective_function.gradient(self.x, out=self.x_update)\n",
    "            self.x_update *= -self.rate\n",
    "            self.x += self.x_update\n",
    "        else:\n",
    "            self.x += -self.rate * self.objective_function.grad(self.x)    \n",
    "\n",
    "    def update_objective(self):\n",
    "        self.loss.append(self.objective_function(self.x))\n",
    "        \n",
    "\n",
    "\n",
    "class FISTA(Algorithm):\n",
    "    '''Fast Iterative Shrinkage-Thresholding Algorithm\n",
    "    \n",
    "    Beck, A. and Teboulle, M., 2009. A fast iterative shrinkage-thresholding \n",
    "    algorithm for linear inverse problems. \n",
    "    SIAM journal on imaging sciences,2(1), pp.183-202.\n",
    "    \n",
    "    Parameters:\n",
    "      x_init: initial guess\n",
    "      f: data fidelity\n",
    "      g: regularizer\n",
    "      h:\n",
    "      opt: additional algorithm \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        '''initialisation can be done at creation time if all \n",
    "        proper variables are passed or later with set_up'''\n",
    "        super(FISTA, self).__init__()\n",
    "        self.f = None\n",
    "        self.g = None\n",
    "        self.invL = None\n",
    "        self.t_old = 1\n",
    "        args = ['x_init', 'f', 'g', 'opt']\n",
    "        for k,v in kwargs.items():\n",
    "            if k in args:\n",
    "                args.pop(args.index(k))\n",
    "        if len(args) == 0:\n",
    "            return self.set_up(x_init=kwargs['x_init'],\n",
    "                               f=kwargs['f'],\n",
    "                               g=kwargs['g'],\n",
    "                               opt=kwargs['opt'])\n",
    "    \n",
    "    def set_up(self, x_init, f=None, g=None, opt=None):\n",
    "        \n",
    "        # default inputs\n",
    "        if f   is None: \n",
    "            self.f = ZeroFun()\n",
    "        else:\n",
    "            self.f = f\n",
    "        if g   is None:\n",
    "            g = ZeroFun()\n",
    "        else:\n",
    "            self.g = g\n",
    "        \n",
    "        # algorithmic parameters\n",
    "        if opt is None: \n",
    "            opt = {'tol': 1e-4, 'iter': 1000, 'memopt':False}\n",
    "        \n",
    "        self.max_iteration = opt['iter'] if 'iter' in opt.keys() else 1000\n",
    "        self.tol = opt['tol'] if 'tol' in opt.keys() else 1e-4\n",
    "        memopt = opt['memopt'] if 'memopt' in opt.keys() else False\n",
    "        self.memopt = memopt\n",
    "            \n",
    "        # initialization\n",
    "        if memopt:\n",
    "            self.y = x_init.clone()\n",
    "            self.x_old = x_init.clone()\n",
    "            self.x = x_init.clone()\n",
    "            self.u = x_init.clone()\n",
    "        else:\n",
    "            self.x_old = x_init.copy()\n",
    "            self.y = x_init.copy()\n",
    "        \n",
    "        #timing = numpy.zeros(max_iter)\n",
    "        #criter = numpy.zeros(max_iter)\n",
    "        \n",
    "    \n",
    "        self.invL = 1/f.L\n",
    "        \n",
    "        self.t_old = 1\n",
    "        \n",
    "    def should_stop(self):\n",
    "        '''stopping cryterion, currently only based on number of iterations'''\n",
    "        return self.iteration >= self.max_iteration\n",
    "    \n",
    "    def update(self):\n",
    "    # algorithm loop\n",
    "    #for it in range(0, max_iter):\n",
    "    \n",
    "        if self.memopt:\n",
    "            # u = y - invL*f.grad(y)\n",
    "            # store the result in x_old\n",
    "            self.f.gradient(self.y, out=self.u)\n",
    "            self.u.__imul__( -self.invL )\n",
    "            self.u.__iadd__( self.y )\n",
    "            # x = g.prox(u,invL)\n",
    "            self.g.proximal(self.u, self.invL, out=x)\n",
    "            \n",
    "            self.t = 0.5*(1 + numpy.sqrt(1 + 4*(self.t_old**2)))\n",
    "            \n",
    "            # y = x + (t_old-1)/t*(x-x_old)\n",
    "            self.x.subtract(self.x_old, out=self.y)\n",
    "            self.y.__imul__ ((self.t_old-1)/self.t)\n",
    "            self.y.__iadd__( self.x )\n",
    "            \n",
    "            self.x_old.fill(self.x)\n",
    "            self.t_old = self.t\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            u = self.y - self.invL*self.f.grad(self.y)\n",
    "            \n",
    "            self.x = self.g.prox(u,self.invL)\n",
    "            \n",
    "            self.t = 0.5*(1 + numpy.sqrt(1 + 4*(self.t_old**2)))\n",
    "            \n",
    "            self.y = self.x + (self.t_old-1)/self.t*(self.x-self.x_old)\n",
    "            \n",
    "            self.x_old = self.x.copy()\n",
    "            self.t_old = self.t\n",
    "        \n",
    "    def update_objective(self):     \n",
    "        self.loss.append( self.f(self.x) + self.g(self.x) )\n",
    "        \n",
    "class cilPluginToSIRFFactory(object):\n",
    "    '''Factory to create SIRF wrappers for CCPi CIL plugins'''\n",
    "    @staticmethod\n",
    "    def getInstance(thetype, **kwargs):\n",
    "        '''Returns an instance of a CCPi CIL plugin wrapped to work on SIRF DataContainers'''\n",
    "        obj = thetype(**kwargs)\n",
    "        orig_prox = obj.prox\n",
    "        obj.prox = cilPluginToSIRFFactory.prox(orig_prox, \n",
    "                                               obj.__class__.__name__)\n",
    "        return obj\n",
    "    @staticmethod\n",
    "    def prox(method, classname):\n",
    "        def wrapped(x, sigma):\n",
    "            '''Wrapped method'''\n",
    "            print(\"calling \", classname)\n",
    "            if isinstance(x, sirf.Gadgetron.ImageData):\n",
    "                # if the data is MR => complex we operate the regulariser\n",
    "                # only on the real part\n",
    "                X = x.as_array()\n",
    "                out = method(cilDataContainer(X.real), sigma)\n",
    "                X.real[:] = out.as_array()\n",
    "                y = x.copy()\n",
    "                y.fill(X)\n",
    "            else:\n",
    "                out = method(x, sigma)\n",
    "                y = x.copy()\n",
    "                y.fill(out.as_array())\n",
    "            print(\"done\")\n",
    "                \n",
    "            return y\n",
    "        return wrapped\n",
    "    \n",
    "def PowerMethodNonsquare(op,numiters , x0=None):\n",
    "    # Initialise random\n",
    "    \n",
    "    if x0 is None:\n",
    "        #x0 = op.create_image_data()\n",
    "        x0 = op.allocate_direct()\n",
    "        x0.fill(numpy.random.randn(*x0.shape))\n",
    "    \n",
    "    s = numpy.zeros(numiters)\n",
    "    # Loop\n",
    "    for it in numpy.arange(numiters):\n",
    "        x1 = op.adjoint(op.direct(x0))\n",
    "        #x1norm = numpy.sqrt((x1*x1).sum())\n",
    "        x1norm = x1.norm()\n",
    "        #print (\"x0 **********\" ,x0)\n",
    "        #print (\"x1 **********\" ,x1)\n",
    "        s[it] = (x1*x0.conjugate()).sum() / (x0*x0.conjugate()).sum()\n",
    "        x0 = (1.0/x1norm)*x1\n",
    "    return numpy.sqrt(s[-1]), numpy.sqrt(s), x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data and AcquisitionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process command-line options\n",
    "data_file = 'simulated_MR_2D_cartesian_Grappa2.h5'\n",
    "data_path = None\n",
    "\n",
    "if data_path is None:\n",
    "    data_path = petmr_data_path('mr')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# locate the input data file\n",
    "input_file = existing_filepath(data_path, data_file)\n",
    "\n",
    "# acquisition data will be read from an HDF file input_data\n",
    "acq_data = AcquisitionData(input_file)\n",
    "\n",
    "# pre-process acquisition data\n",
    "print('---\\n pre-processing acquisition data...')\n",
    "# the following function runs a GadgetChain data processor\n",
    "# preprocessed_data = preprocess_acquisition_data(acq_data)\n",
    "gadget_chain = ['NoiseAdjustGadget', \\\n",
    "                'AsymmetricEchoAdjustROGadget', \\\n",
    "                'RemoveROOversamplingGadget']\n",
    "ap = AcquisitionDataProcessor( gadget_chain )\n",
    "ap.set_input( acq_data )\n",
    "ap.process()\n",
    "preprocessed_data = ap.get_output()\n",
    "\n",
    "\n",
    "# perform reconstruction\n",
    "recon = CartesianGRAPPAReconstructor()\n",
    "recon.set_input( preprocessed_data )\n",
    "recon.compute_gfactors( False )\n",
    "print('---\\n reconstructing...')\n",
    "recon.process()\n",
    "# for undersampled acquisition data GRAPPA computes Gfactor images\n",
    "# in addition to reconstructed ones\n",
    "image_data = recon.get_output()\n",
    "\n",
    "image_array = image_data.as_array()\n",
    "title = 'Reconstructed image data (magnitude)'\n",
    "show_3D_array(abs(image_array), suptitle = title, label = 'slice', \\\n",
    "              xlabel = 'samples', ylabel = 'readouts', show = False)\n",
    "\n",
    "# compute coil sensitivity maps\n",
    "csms = CoilSensitivityData()\n",
    "print('---\\n sorting acquisition data...')\n",
    "preprocessed_data.sort()\n",
    "print('---\\n computing sensitivity maps...')\n",
    "csms.calculate( preprocessed_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create acquisition model based on the acquisition parameters\n",
    "# stored in preprocessed_data and image parameters stored in\n",
    "# image_data\n",
    "acq_model = AcquisitionModel( preprocessed_data, image_data )\n",
    "acq_model.set_coil_sensitivity_maps( csms )\n",
    "\n",
    "# use the acquisition model (forward projection) to simulate acquisition data\n",
    "simulated_data = acq_model.forward( image_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIL/SIRF integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the objective function as Norm2square\n",
    "$$\n",
    "c || A x - b ||^2\n",
    "$$\n",
    "where $c$ is a constant, $A$ is the linear operator and $b$ are the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Norm2square objective function\n",
    "# c || Ax - b ||^2\n",
    "norm2sq = Norm2sq( A = acq_model , b = preprocessed_data , c = 1)\n",
    "# create a random initialisation image by shuffling the real\n",
    "# image data. \n",
    "x_init = image_data.copy()\n",
    "x = x_init.as_array().flatten()\n",
    "numpy.random.shuffle(x)\n",
    "x = numpy.reshape(x, x_init.as_array().shape)\n",
    "x_init.fill(x)\n",
    "del x\n",
    "\n",
    "show_3D_array(x_init.as_array().real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear operator $A$, the AcquisitionModel, should satisfy this: \n",
    "\n",
    "$Ax_0\\times y_0 = y_0 \\times A^Tx_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if <Ax0,y0> = <y0, A^Tx0>\n",
    "y0 = simulated_data.copy()\n",
    "x = y0.as_array().flatten()\n",
    "numpy.random.shuffle(x)\n",
    "x = numpy.reshape(x, y0.as_array().shape)\n",
    "y0.fill(x)\n",
    "del x     \n",
    "x0 = x_init\n",
    "fx0 = acq_model.direct(x0)\n",
    "by0 = acq_model.adjoint(y0)\n",
    "a = fx0.dot(y0)\n",
    "b = by0.dot(x0)\n",
    "numpy.testing.assert_almost_equal(abs((a-b)/a), 0, decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Lipschitz constant\n",
    "lipschitz = PowerMethodNonsquare( acq_model , numiters = 10 , x0 = x_init) [0] \n",
    "norm2sq.L = lipschitz  \n",
    "print (\"Lipschitz \" , norm2sq.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# create a Gradient Descent algorithm which minimises norm2sq\n",
    "gd = GradientDescent(x_init=x_init, \n",
    "           objective_function=norm2sq, rate=lipschitz/3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.max_iteration = 20\n",
    "pixval = []\n",
    "gadgval = image_data.as_array()[0][46][160]\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "im = fig.add_subplot(122)\n",
    "im.imshow(abs(x_init.as_array()[0]))\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in gd:\n",
    "    ax.clear()\n",
    "    pixval.append( gd.get_output().as_array()[0][46][160])\n",
    "    print (\"\\rIteration {} Loss: {} pix {}\".format(gd.iteration, \n",
    "           gd.get_current_loss(), pixval[-1]/gadgval))\n",
    "    ax.semilogy([val/gd.loss[0] for val in gd.loss])\n",
    "    im.imshow(abs(gd.get_output().as_array()[0]))\n",
    "    fig.canvas.draw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_3D_array(gd.get_output().as_array().real, suptitle='Gradient Descent (magnitude)')\n",
    "\n",
    "#%%\n",
    "# USE FISTA with Regularisation   \n",
    "no_regulariser = ZeroFun()\n",
    "# create a regulariser with the Factory\n",
    "regulariser = cilPluginToSIRFFactory.getInstance(FGP_TV, \n",
    "                                       lambdaReg=.1,\n",
    "                                       iterationsTV=300,\n",
    "                                       tolerance=1e-5,\n",
    "                                       methodTV=0,\n",
    "                                       nonnegativity=0,\n",
    "                                       printing=0,\n",
    "                                       device='cpu')\n",
    "options = {'tol': 1e-4, 'iter': 10, 'memopt':False}\n",
    "\n",
    "norm2sq.L = lipschitz*3.\n",
    "# create a FISTA algorithm instance\n",
    "fista = FISTA(x_init=x_init, f=norm2sq, g=regulariser, opt=options)\n",
    "fpixval = []\n",
    "#%%\n",
    "# run FISTA\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "im = fig.add_subplot(122)\n",
    "im.imshow(abs(x_init.as_array()[0]))\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "for i,el in enumerate(fista):\n",
    "    ax.clear()\n",
    "    fpixval.append( fista.get_output().as_array()[0][46][160])\n",
    "    if i%1 == 0:\n",
    "        print (\"\\rFISTA Iteration {} Loss: {} pix {}\".format(fista.iteration, \n",
    "           fista.get_current_loss(), fpixval[-1]/gadgval))\n",
    "        ax.semilogy([val/fista.loss[0] for val in fista.loss])\n",
    "        im.imshow(abs(fista.get_output().as_array()[0]))\n",
    "        fig.canvas.draw()\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'tol': 1e-4, 'iter': 20, 'memopt':False}\n",
    "fista_noreg = FISTA(x_init=x_init, f=norm2sq, g=no_regulariser, opt=options)\n",
    "fpixval = []\n",
    "#%%\n",
    "# run FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "im = fig.add_subplot(122)\n",
    "im.imshow(abs(x_init.as_array()[0]))\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i,el in enumerate(fista_noreg):\n",
    "    ax.clear()\n",
    "    fpixval.append( fista_noreg.get_output().as_array()[0][46][160])\n",
    "    if i%1 == 0:\n",
    "        print (\"\\rFISTA Iteration {} Loss: {} pix {}\".format(\n",
    "            fista_noreg.iteration, \n",
    "            fista_noreg.get_current_loss(), \n",
    "            fpixval[-1]/gadgval))\n",
    "        ax.semilogy([val/fista_noreg.loss[0] for val in fista_noreg.loss])\n",
    "        im.imshow(abs(fista_noreg.get_output().as_array()[0]))\n",
    "        fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot convergence\n",
    "fig = plt.figure()\n",
    "ax = plt.plot([gd.loss[i]/max(gd.loss) for i in range(10)], label='Gradient Descent')\n",
    "#ax = plt.plot([el/max(fista_noreg.loss) for el in fista_noreg.loss], label='FISTA')\n",
    "ax = plt.plot([el/max(fista.loss) for el in fista.loss], label='FISTA + FGP_TV')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# plot the results\n",
    "fig = plt.figure()\n",
    "#ax1 = plt.subplot(1,4,1)\n",
    "#plt.imshow(abs(image_data.as_array()[0]), cmap='gray')\n",
    "#plt.clim(0, 5)\n",
    "#ax1.set_title('Initial Data')\n",
    "#ax2 = plt.subplot(1,4,2)\n",
    "ax2 = plt.subplot(1,2,1)\n",
    "plt.imshow(abs(gd.get_output().as_array()[0]), cmap='gray')\n",
    "plt.clim(0, 1.)\n",
    "ax2.set_title('Gradient Descent')\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "#ax2 = plt.subplot(1,4,3)\n",
    "#ax2 = plt.subplot(1,2,1)\n",
    "#plt.imshow(abs(fista_noreg.get_output().as_array()[0]), cmap='gray')\n",
    "#plt.clim(0, 5)\n",
    "#ax2.set_title('FISTA no reg')\n",
    "#ax2 = plt.subplot(1,4,4)\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "plt.imshow(abs(fista.get_output().as_array()[0]), cmap='gray')\n",
    "plt.clim(0, 1.)\n",
    "ax2.set_title('FISTA + FGP_TV')\n",
    "plt.show()\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(range(1,5),range(4)):\n",
    "    print (i,j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
