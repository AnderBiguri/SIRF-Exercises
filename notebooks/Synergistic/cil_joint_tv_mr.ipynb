{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint TV for multi-contrast MR\n",
    "This demonstration shows how to do image reconstruction using gradient descent for different modalities. \n",
    "\n",
    "It builds on the the notebook *acquisition_model_mr_pet_ct.ipynb*. The first part of the notebook which creates acquisition models and simulates data from the brainweb is the same code but with fewer comments. If anything is unclear, then please refer to the other notebook to get some further information.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "You could export it as a Python file and run it one go, but that might\n",
    "make little sense as the figures are not labelled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Christoph Kolbitsch, Edoardo Pasca\n",
    "First version: 23rd of April 2021  \n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.  \n",
    "Copyright 2015 - 2019 University College London.   \n",
    "Copyright 2021 Physikalisch-Technische Bundesanstalt.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure figures appears inline and animations works\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure everything is installed that we need\n",
    "!pip install brainweb nibabel --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import brainweb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "# Import MR functionality\n",
    "import sirf.Gadgetron as mr\n",
    "\n",
    "from sirf.Utilities import examples_data_path\n",
    "from cil.framework import  AcquisitionGeometry, BlockDataContainer, BlockGeometry\n",
    "from cil.optimisation.functions import Function, OperatorCompositionFunction, SmoothMixedL21Norm, L1Norm, L2NormSquared, BlockFunction, MixedL21Norm, IndicatorBox, TotalVariation, LeastSquares, ZeroFunction\n",
    "from cil.optimisation.operators import GradientOperator, BlockOperator, ZeroOperator, CompositionOperator,LinearOperator\n",
    "from cil.optimisation.algorithms import PDHG, FISTA, GD\n",
    "from cil.plugins.ccpi_regularisation.functions import FGP_TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define some handy function definitions\n",
    "# To make subsequent code cleaner, we have a few functions here. You can ignore\n",
    "# ignore them when you first see this demo.\n",
    "\n",
    "def plot_2d_image(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    \"\"\"Customized version of subplot to plot 2D image\"\"\"\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def crop_and_fill(templ_im, vol):\n",
    "    \"\"\"Crop volumetric image data and replace image content in template image object\"\"\"\n",
    "    # Get size of template image and crop\n",
    "    idim_orig = templ_im.as_array().shape\n",
    "    idim = (1,)*(3-len(idim_orig)) + idim_orig\n",
    "    offset = (numpy.array(vol.shape) - numpy.array(idim)) // 2\n",
    "    vol = vol[offset[0]:offset[0]+idim[0], offset[1]:offset[1]+idim[1], offset[2]:offset[2]+idim[2]]\n",
    "    \n",
    "    # Make a copy of the template to ensure we do not overwrite it\n",
    "    templ_im_out = templ_im.copy()\n",
    "    \n",
    "    # Fill image content \n",
    "    templ_im_out.fill(numpy.reshape(vol, idim_orig))\n",
    "    return(templ_im_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get brainweb data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download and use data from the brainweb. We will use a FDG image for PET and the PET uMAP for CT. MR usually provides qualitative images with an image contrast proportional to difference in T1, T2 or T2* depending on the sequence parameters. Nevertheless, we will make our life easy, by directly using the T1 map provided by the brainweb for MR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, url= sorted(brainweb.utils.LINKS.items())[0]\n",
    "files = brainweb.get_file(fname, url, \".\")\n",
    "data = brainweb.load_file(fname)\n",
    "\n",
    "brainweb.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm([fname], desc=\"mMR ground truths\", unit=\"subject\"):\n",
    "    vol = brainweb.get_mmr_fromfile(f, petNoise=1, t1Noise=0.75, t2Noise=0.75, petSigma=1, t1Sigma=1, t2Sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2_arr  = vol['T2']\n",
    "T1_arr   = vol['T1']\n",
    "\n",
    "# Normalise image data\n",
    "T2_arr /= numpy.max(T2_arr)\n",
    "T1_arr /= numpy.max(T1_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display it\n",
    "plt.figure();\n",
    "slice_show = T2_arr.shape[0]//2\n",
    "plot_2d_image([1,2,1], T2_arr[slice_show, 100:-100, 100:-100], 'T2', cmap=\"Greys_r\")\n",
    "plot_2d_image([1,2,2], T1_arr[slice_show, 100:-100, 100:-100], 'T1', cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will set up the acquisition models for __MR__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create MR AcquisitionData\n",
    "mr_acq = mr.AcquisitionData(examples_data_path('MR') + '/grappa2_1rep.h5')\n",
    "mr_acq = mr.AcquisitionData(examples_data_path('MR') + '/simulated_MR_2D_cartesian_Grappa2.h5')\n",
    "#mr_acq = mr.AcquisitionData('/home/sirfuser/devel/SIRF-Exercises/data/MR/PTB_ACRPhantom_GRAPPA/ptb_resolutionphantom_fully_ismrmrd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. calculate CSM\n",
    "preprocessed_data = mr.preprocess_acquisition_data(mr_acq)\n",
    "preprocessed_data.sort()\n",
    "\n",
    "csm = mr.CoilSensitivityData()\n",
    "csm.smoothness = 50\n",
    "csm.calculate(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. calculate image template\n",
    "recon = mr.FullySampledReconstructor()\n",
    "recon.set_input(preprocessed_data)\n",
    "recon.process()\n",
    "im_mr = recon.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display it\n",
    "plt.figure();\n",
    "csm_arr = numpy.abs(csm.as_array())\n",
    "im_mr_arr = numpy.abs(im_mr.as_array())\n",
    "\n",
    "plot_2d_image([1,3,1], csm_arr[0, 0, :, :], 'Coil 0', cmap=\"Greys_r\")\n",
    "plot_2d_image([1,3,2], csm_arr[2, 0, :, :], 'Coil 2', cmap=\"Greys_r\")\n",
    "plot_2d_image([1,3,3], im_mr_arr[0, :, :], 'Im', cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_step_1 = preprocessed_data.parameter_info('kspace_encode_step_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ky_0_idx = len(encode_step_1)//2\n",
    "ky_us_idx = numpy.concatenate((numpy.arange(0,57), numpy.arange(86,len(encode_step_1))), axis=0)\n",
    "ky_num_fs = 20\n",
    "ky_num_us = 60\n",
    "acq_idx_t1 = numpy.arange(ky_0_idx-ky_num_fs//2, ky_0_idx+ky_num_fs//2)\n",
    "acq_idx_t1 = numpy.concatenate((acq_idx_t1, numpy.asarray(random.sample(list(ky_us_idx), ky_num_us))), axis=0)\n",
    "\n",
    "acq_idx_t2 = numpy.arange(ky_0_idx-ky_num_fs//2, ky_0_idx+ky_num_fs//2)\n",
    "acq_idx_t2 = numpy.concatenate((acq_idx_t2, numpy.asarray(random.sample(list(ky_us_idx), ky_num_us))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(encode_step_1, numpy.ones(encode_step_1.shape), 'b.')\n",
    "plt.plot(encode_step_1[acq_idx_t1], numpy.ones(encode_step_1[acq_idx_t1].shape), 'r.')\n",
    "plt.plot(encode_step_1[acq_idx_t2], numpy.ones(encode_step_1[acq_idx_t2].shape), 'g.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling\n",
    "if True:\n",
    "    acq_dat_t1 = preprocessed_data.new_acquisition_data(empty=True)\n",
    "\n",
    "    # Create raw data\n",
    "    for jnd in range(len(acq_idx_t1)):\n",
    "        cacq = preprocessed_data.acquisition(acq_idx_t1[jnd])\n",
    "        acq_dat_t1.append_acquisition(cacq)\n",
    "        \n",
    "    acq_dat_t1.sort()     \n",
    "    acq_mod_mr_t1 = mr.AcquisitionModel(acq_dat_t1, im_mr)\n",
    "    acq_mod_mr_t1.set_coil_sensitivity_maps(csm)\n",
    "    \n",
    "    \n",
    "    acq_dat_t2 = preprocessed_data.new_acquisition_data(empty=True)\n",
    "\n",
    "    # Create raw data\n",
    "    for jnd in range(len(acq_idx_t2)):\n",
    "        cacq = preprocessed_data.acquisition(acq_idx_t2[jnd])\n",
    "        acq_dat_t2.append_acquisition(cacq)\n",
    "        \n",
    "    acq_dat_t2.sort()     \n",
    "    acq_mod_mr_t2 = mr.AcquisitionModel(acq_dat_t2, im_mr)\n",
    "    acq_mod_mr_t2.set_coil_sensitivity_maps(csm)\n",
    "    \n",
    "else:\n",
    "    acq_mod_mr_t1 = mr.AcquisitionModel(preprocessed_data, im_mr)\n",
    "    acq_mod_mr_t1.set_coil_sensitivity_maps(csm)\n",
    "\n",
    "    acq_mod_mr_t2 = mr.AcquisitionModel(preprocessed_data, im_mr)\n",
    "    acq_mod_mr_t2.set_coil_sensitivity_maps(csm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the acquisition models to create simulated raw data and then do a simple reconstruction to have some initial images (i.e. starting point) for our gradient descent algorithms. For each modality we will:\n",
    "\n",
    " * Fill an image template (`im_mr`, `im_pet`, `im_ct`)\n",
    " * Create raw data (`raw_mr`, `raw_pet`, `raw_ct`)\n",
    " * Reconstruct an initial guess of our image using `backward`/`adjoint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MR\n",
    "im_mr_t1 = crop_and_fill(im_mr, T1_arr)\n",
    "raw_mr_t1 = acq_mod_mr_t1.forward(im_mr_t1)\n",
    "bwd_mr_t1 = acq_mod_mr_t1.backward(raw_mr_t1)\n",
    "\n",
    "im_mr_t2 = crop_and_fill(im_mr, T2_arr)\n",
    "raw_mr_t2 = acq_mod_mr_t2.forward(im_mr_t2)\n",
    "bwd_mr_t2 = acq_mod_mr_t2.backward(raw_mr_t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display it\n",
    "plt.figure();\n",
    "slice_show = bwd_mr_t1.as_array().shape[0]//2\n",
    "plot_2d_image([1,2,1], numpy.abs(bwd_mr_t2.as_array())[slice_show, :, :], 'T2', cmap=\"Greys_r\")\n",
    "plot_2d_image([1,2,2], numpy.abs(bwd_mr_t1.as_array())[slice_show, :, :], 'T1', cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOINT TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionMap(LinearOperator):\n",
    "    \n",
    "    def __init__(self, domain_geometry, index, range_geometry=None):\n",
    "        \n",
    "        self.index = index\n",
    "        if range_geometry is None:\n",
    "            range_geometry = domain_geometry.geometries[self.index]\n",
    "            \n",
    "        super(ProjectionMap, self).__init__(domain_geometry=domain_geometry, \n",
    "                                           range_geometry=range_geometry)   \n",
    "        \n",
    "    def direct(self,x,out=None):\n",
    "                        \n",
    "        if out is None:\n",
    "            return x.get_item(self.index)\n",
    "        else:\n",
    "            out.fill(x.get_item(self.index))\n",
    "    \n",
    "    def adjoint(self,x, out=None):\n",
    "        \n",
    "        if out is None:\n",
    "            tmp = self.domain_geometry().allocate()\n",
    "            tmp[self.index].fill(x)            \n",
    "            return tmp\n",
    "        else:\n",
    "            out[self.index].fill(x) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothJointTV(Function):\n",
    "              \n",
    "    def __init__(self, epsilon, axis, lambda_par):\n",
    "                \n",
    "        r'''\n",
    "        :param epsilon: smoothing parameter making MixedL21Norm differentiable \n",
    "        '''\n",
    "\n",
    "        #TODO L=??\n",
    "        super(SmoothJointTV, self).__init__(L=numpy.sqrt(8))\n",
    "        \n",
    "        # smoothing parameter\n",
    "        self.epsilon = epsilon   \n",
    "        \n",
    "        # GradientOperator\n",
    "        #self.grad = GradientOperator(bwd_mr_t1, backend='numpy', correlation='SpaceChannels')\n",
    "        \n",
    "        ig = ImageGeometry(voxel_num_z = 1,voxel_num_y = 3, voxel_num_x = 4)\n",
    "        FDy = FiniteDifferenceOperator(bwd_mr_t1, direction=1)\n",
    "        FDx = FiniteDifferenceOperator(bwd_mr_t1, direction=2)\n",
    "        self.grad = BlockOperator(FDy, FDx)\n",
    "        \n",
    "        \n",
    "        # Which variable to differentiate\n",
    "        self.axis = axis\n",
    "        \n",
    "        if self.epsilon==0:\n",
    "            raise ValueError('Working with smooth JTV atm')\n",
    "            \n",
    "        self.lambda_par=lambda_par    \n",
    "                                    \n",
    "                            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        r\"\"\" x is BlockDataContainer that contains (u,v). Actually x is a BlockDataContainer that contains 2 BDC.\n",
    "        \"\"\"\n",
    "        if not isinstance(x, BlockDataContainer):\n",
    "            raise ValueError('__call__ expected BlockDataContainer, got {}'.format(type(x))) \n",
    "\n",
    "        tmp = numpy.abs((self.lambda_par*self.grad.direct(x.get_item(0)).pnorm(2).power(2) + (1-self.lambda_par)*self.grad.direct(x.get_item(1)).pnorm(2).power(2)+\\\n",
    "              self.epsilon**2).sqrt().sum())\n",
    "        #print('JTV', tmp)\n",
    "        return tmp    \n",
    "                        \n",
    "             \n",
    "    def gradient(self, x, out=None):\n",
    "        \n",
    "        denom = (self.lambda_par*self.grad.direct(x.get_item(0)).pnorm(2).power(2) + (1-self.lambda_par)*self.grad.direct(x.get_item(1)).pnorm(2).power(2)+\\\n",
    "              self.epsilon**2).sqrt()         \n",
    "        \n",
    "        if self.axis==0:            \n",
    "            num = self.lambda_par*self.grad.direct(x.get_item(0))                        \n",
    "        else:            \n",
    "            num = (1-self.lambda_par)*self.grad.direct(x.get_item(1))            \n",
    "\n",
    "        if out is None:    \n",
    "            tmp = self.grad.range.allocate()\n",
    "            tmp[self.axis].fill(self.grad.adjoint(num.divide(denom)))\n",
    "            return tmp\n",
    "        else:                                \n",
    "            self.grad.adjoint(num.divide(denom), out=out[self.axis])\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.framework import ImageGeometry\n",
    "from cil.optimisation.operators import FiniteDifferenceOperator, BlockOperator\n",
    "ig = ImageGeometry(voxel_num_z = 1,voxel_num_y = 3, voxel_num_x = 4)\n",
    "FDy = FiniteDifferenceOperator(bwd_mr_t1, direction=1)\n",
    "FDx = FiniteDifferenceOperator(bwd_mr_t1, direction=2)\n",
    "B = BlockOperator(FDy, FDx)\n",
    "x = bwd_mr_t1.clone()\n",
    "res = B.direct(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_opt_t1 = numpy.squeeze(numpy.abs(bwd_mr_t1.as_array()))\n",
    "\n",
    "plt.figure()\n",
    "plot_2d_image([1,2,1], numpy.squeeze(numpy.abs(bwd_mr_t1.as_array()[0, 70:130, 70:130])), 'T1 pseudo inv', cmap=\"Greys_r\")\n",
    "plot_2d_image([1,2,2], numpy.squeeze(numpy.abs(res.get_item(0).as_array()[0, 70:130, 70:130])), 'FD_x_y', cmap=\"Greys_r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_it_fista = 10\n",
    "x_init = bwd_mr_t1.clone()\n",
    "\n",
    "t1 = time.time()\n",
    "f = LeastSquares(acq_mod_mr_t1, raw_mr_t1, c=1)\n",
    "print('LS {:3.2f}s'.format((time.time() - t1)))\n",
    "\n",
    "G = ZeroFunction()\n",
    "\n",
    "# Run FISTA for least squares\n",
    "t1 = time.time()\n",
    "fista = FISTA(x_init=x_init, f=f, g=G)\n",
    "fista.max_iteration = num_it_fista\n",
    "fista.update_objective_interval = 2\n",
    "print('SETUP {:3.2f}s'.format((time.time() - t1)))\n",
    "\n",
    "t1 = time.time()\n",
    "fista.run(100, verbose=True)\n",
    "print('FISTA {:3.2f}s'.format((time.time() - t1)))\n",
    "\n",
    "im_opt_t1 = numpy.squeeze(numpy.abs(fista.get_output().as_array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FISTA with TV\n",
    "alpha = 0.2\n",
    "G = alpha * FGP_TV(max_iteration=10, device='cpu')\n",
    "\n",
    "t1 = time.time()\n",
    "fista = FISTA(x_init=x_init, f=f, g=G)\n",
    "fista.max_iteration = num_it_fista\n",
    "fista.update_objective_interval = 2\n",
    "print('SETUP {:3.2f}s'.format((time.time() - t1)))\n",
    "\n",
    "t1 = time.time()\n",
    "fista.run(100, verbose=True)\n",
    "print('FISTA {:3.2f}s'.format((time.time() - t1)))\n",
    "\n",
    "im_opt_t1_tv = numpy.squeeze(numpy.abs(fista.get_output().as_array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_2d_image([2,3,1], numpy.squeeze(numpy.abs(bwd_mr_t1.as_array()[0, 70:130, 70:130])), 'T1 pseudo inv', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,2], im_opt_t1[70:130, 70:130], 'T1 FISTA', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,5], im_opt_t1_tv[70:130, 70:130], 'T1 FISTA TV', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,3], numpy.squeeze(numpy.abs(im_mr_t1.as_array()[0, 70:130, 70:130])), 'T1 GT', cmap=\"Greys_r\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = 0.001\n",
    "alpha2 = 0.001\n",
    "lambda_par = 0.5\n",
    "epsilon = 1e-4\n",
    "\n",
    "bg = BlockGeometry(bwd_mr_t1, bwd_mr_t2)\n",
    "\n",
    "L1 = ProjectionMap(bg,index=0)\n",
    "L2 = ProjectionMap(bg,index=1)\n",
    "\n",
    "f1 = 0.5*L2NormSquared(b=raw_mr_t1)\n",
    "f2 = 0.5*L2NormSquared(b=raw_mr_t2)\n",
    "\n",
    "JTV1 = alpha1*SmoothJointTV(epsilon=epsilon, axis=0, lambda_par = lambda_par )\n",
    "JTV2 = alpha2*SmoothJointTV(epsilon=epsilon, axis=1, lambda_par = 1-lambda_par)\n",
    "objective1 = OperatorCompositionFunction(f1, CompositionOperator(acq_mod_mr_t1,L1)) + JTV1\n",
    "objective2 = OperatorCompositionFunction(f2, CompositionOperator(acq_mod_mr_t2,L2)) + JTV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = bg.allocate(0.0)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "\n",
    "    gd1 = GD(x0, objective1, alpha=1e9, \\\n",
    "          max_iteration = 10, update_objective_interval = 1)\n",
    "    gd1.run(verbose=1)\n",
    "    \n",
    "\n",
    "    gd2 = GD(gd1.solution, objective2, alpha=1e9,\\\n",
    "          max_iteration = 10, update_objective_interval = 1)\n",
    "    gd2.run(verbose=1) \n",
    "    \n",
    "    x0.fill(gd2.solution)\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_opt_t1 = numpy.squeeze(numpy.abs(x0.get_item(0).as_array()))\n",
    "im_opt_t2 = numpy.squeeze(numpy.abs(x0.get_item(1).as_array()))\n",
    "\n",
    "plt.figure()\n",
    "plot_2d_image([2,3,1], numpy.squeeze(numpy.abs(bwd_mr_t1.as_array()[0, 70:130, 70:130])), 'T1 pseudo inv', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,2], im_opt_t1[70:130, 70:130], 'T1 JTV', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,3], numpy.squeeze(numpy.abs(im_mr_t1.as_array()[0, 70:130, 70:130])), 'T1 GT', cmap=\"Greys_r\") \n",
    "\n",
    "plot_2d_image([2,3,4], numpy.squeeze(numpy.abs(bwd_mr_t2.as_array()[0, 70:130, 70:130])), 'T2 pseudo inv', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,5], im_opt_t2[70:130, 70:130], 'T2 JTV', cmap=\"Greys_r\")\n",
    "plot_2d_image([2,3,6], numpy.squeeze(numpy.abs(im_mr_t2.as_array()[0, 70:130, 70:130])), 'T2 GT', cmap=\"Greys_r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
