{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of basic image manipulation with SIRF\n",
    "This demonstration shows how to read images and data, display them.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "You could export it as a Python file and run it one go, but that might\n",
    "make little sense as the figures are not labelled.\n",
    "\n",
    "This notebook constitutes the first half of the PET [display_and_projection](../PET/display_and_projection.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kris Thielemans, Richard Brown\n",
    "First version: 8th of September 2016  \n",
    "Second Version: 17th of May 2018\n",
    "Third Version: 23rd of October 2019\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.  \n",
    "Copyright 2015 - 2019 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make sure figures appears inline and animations works\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure everything is installed that we need\n",
    "!pip install brainweb nibabel --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import brainweb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sirf.Utilities import examples_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% First define some handy function definitions\n",
    "# To make subsequent code cleaner, we have a few functions here. You can ignore\n",
    "# ignore them when you first see this demo.\n",
    "# They have (minimal) documentation using Python docstrings such that you \n",
    "# can do for instance \"help(subplot_)\"\n",
    "#\n",
    "\n",
    "def subplot_(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    \"\"\"Customized version of subplot\"\"\"\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def crop_and_fill(templ_im, vol):\n",
    "    \"\"\"Crop volumetric image data and replace image content in template image object\"\"\"\n",
    "    # Get size of template image and crop\n",
    "    #idim = templ_im.dimensions() # TODO\n",
    "    idim_orig = templ_im.as_array().shape\n",
    "    idim = (1,)*(3-len(idim_orig)) + idim_orig\n",
    "    offset = (numpy.array(vol.shape) - numpy.array(idim)) // 2\n",
    "    vol = vol[offset[0]:offset[0]+idim[0], offset[1]:offset[1]+idim[1], offset[2]:offset[2]+idim[2]]\n",
    "    # Fill image content\n",
    "    templ_im.fill(numpy.reshape(vol, idim_orig))\n",
    "    return(templ_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get brainweb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname, url= sorted(brainweb.utils.LINKS.items())[0]\n",
    "files = brainweb.get_file(fname, url, \".\")\n",
    "data = brainweb.load_file(fname)\n",
    "\n",
    "brainweb.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm([fname], desc=\"mMR ground truths\", unit=\"subject\"):\n",
    "    vol = brainweb.get_mmr_fromfile(f, petNoise=1, t1Noise=0.75, t2Noise=0.75, petSigma=1, t1Sigma=1, t2Sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDG_arr  = vol['PET']\n",
    "T1_arr   = vol['T1']\n",
    "uMap_arr = vol['uMap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display it\n",
    "plt.figure();\n",
    "slice_show = FDG_arr.shape[0]//2\n",
    "subplot_([1,3,1], FDG_arr[slice_show, 100:-100, 100:-100], 'FDG', cmap=\"hot\")\n",
    "subplot_([1,3,2], T1_arr[slice_show, 100:-100, 100:-100], 'T1', cmap=\"Greys_r\")\n",
    "subplot_([1,3,3], uMap_arr[slice_show, 100:-100, 100:-100], 'uMap', cmap=\"bone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use the 'mr' prefix for all Gadgetron-based SIRF functions.\n",
    "# This is done here to explicitly differentiate between SIRF mr functions and \n",
    "# anything else.\n",
    "import sirf.Gadgetron as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need a template MR acquisition data object\n",
    "templ_mr = mr.AcquisitionData(examples_data_path('MR') + '/simulated_MR_2D_cartesian.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a template MR image data\n",
    "#im_mr = mr.ImageData(templ_mr)\n",
    "\n",
    "# TODO \n",
    "# -> work around\n",
    "preprocessed_data = mr.preprocess_acquisition_data(templ_mr)\n",
    "recon = mr.FullySampledReconstructor()\n",
    "recon.set_input(preprocessed_data)\n",
    "recon.process()\n",
    "im_mr = recon.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have got an MR image object and can fill it with the brainweb data. The dimensions won't fit, but we will simply crop the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_mr = crop_and_fill(im_mr, T1_arr)\n",
    "plt.figure();\n",
    "subplot_([1,1,1], numpy.abs(im_mr.as_array())[im_mr.dimensions()[0]//2, :, :], 'MR', cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use the 'ct' prefix for all CIL-based SIRF functions.\n",
    "# This is done here to explicitly differentiate between SIRF ct functions and \n",
    "# anything else.\n",
    "import cil.framework as ct #import ImageGeometry, AcquisitionGeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Create a template CT acquisition geometry\n",
    "N = 120\n",
    "angles = numpy.linspace(0, 360, 50, True, dtype=numpy.float32)\n",
    "offset = 0.4\n",
    "channels = 1\n",
    "ag = ct.AcquisitionGeometry.create_Cone3D((offset,-100, 0), (offset,100,0))\n",
    "ag.set_panel((N,N-2))\n",
    "ag.set_channels(channels)\n",
    "ag.set_angles(angles, angle_unit=ct.AcquisitionGeometry.DEGREE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a template CT image object\n",
    "ig = ag.get_ImageGeometry()\n",
    "im_ct = ig.allocate(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have got an CT image object and can fill it with the brainweb data. The dimensions won't fit, but we will simply crop the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_ct = crop_and_fill(im_ct, uMap_arr)\n",
    "\n",
    "plt.figure();\n",
    "subplot_([1,1,1], im_ct.as_array()[im_ct.as_array().shape[0]//2, :, :], 'CT', cmap=\"bone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use the 'pet' prefix for all STIR-based SIRF functions.\n",
    "# This is done here to explicitly differentiate between SIRF pet functions and \n",
    "# anything else.\n",
    "import sirf.STIR as pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need a template sinogram\n",
    "templ_sino = pet.AcquisitionData(examples_data_path('PET') + \"/mMR/mMR_template_span11.hs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a template PET image object\n",
    "im_pet = pet.ImageData(templ_sino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have got an PET image object and can fill it with the brainweb data. The dimensions won't fit, but we will simply crop the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pet = crop_and_fill(im_pet, FDG_arr)\n",
    "\n",
    "plt.figure();\n",
    "subplot_([1,1,1], im_pet.as_array()[im_pet.dimensions()[0]//2, :, :], 'PET', cmap=\"hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic image manipulations\n",
    "Images (like most other things in SIRF) are represented as *objects*, in this case of type `ImageData`.\n",
    "In practice, this means that you can only manipulate its data via *methods*.\n",
    "\n",
    "Image objects contain the actual voxel values, but also information on the number of voxels,\n",
    "voxel size, etc. There are methods to get this information.\n",
    "\n",
    "There are additional methods for other manipulations, such as basic image arithmetic (e.g.,\n",
    "you can add image objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read in images\n",
    "# Here we will read some images provided with the demo using the ImageData class.\n",
    "# These are in Interfile format. (A text header pointing to a .v file with the binary data).\n",
    "image = im_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% What is an ImageData?\n",
    "# Images are represented by objects with several methods. The most important method \n",
    "# is as_array() which we'll use below.\n",
    "# Let's see what all the methods are.\n",
    "help(pet.ImageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use as_array to extract an array of voxel values\n",
    "# The resulting array as a `numpy` array, as standard in Python.\n",
    "image_array=image.as_array()\n",
    "# We can use the standard `numpy` methods on this array, such as getting its `shape` (i.e. dimensions).\n",
    "print(image_array.shape)\n",
    "# Whenever we want to do something with the image-values, we have to do it via this array.\n",
    "# Let's print a voxel-value roughly in the centre of the object. We can't use the centre because this happens to be 0\n",
    "centre = numpy.array(image_array.shape)//2\n",
    "print(image_array[centre[0], centre[1]+20, centre[2]+20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Manipulate the image data for illustration\n",
    "# Multiply the data with a factor\n",
    "image_array *= 0.01\n",
    "# Stick this new data into the original image object.\n",
    "# (This will not modify the file content, only the variable in memory.)\n",
    "image.fill(image_array)\n",
    "print(image_array[centre[0], centre[1]+20, centre[2]+20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% You can do basic math manipulations with ImageData objects \n",
    "# So the above lines can be done directly on the `image` object\n",
    "image *= 0.01\n",
    "# Let's check\n",
    "image_array=image.as_array()\n",
    "print(image_array[centre[0], centre[1]+20, centre[2]+20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display the middle slice of the image (which is really a 3D volume)\n",
    "# We will use our own imshow function (which was defined above) for brevity.\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure()\n",
    "# Display the slice\n",
    "subplot_([1,1,1], image_array[centre[0], 0:-1, 0:-1], 'image data', cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Some other things to do with ImageData objects\n",
    "print(image.voxel_sizes())\n",
    "another_image=image.clone()\n",
    "an_image_with_fixed_values = image.get_uniform_copy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
