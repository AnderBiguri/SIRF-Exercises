{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "###\n",
    "# Demonstration of MR reconstruction with CCP PET-MR Software\n",
    "#\n",
    "# This demonstration shows how to hande undersampled data\n",
    "# and how to write a simple iterative reconstruction algorithm with\n",
    "# the acquisition model.\n",
    "#\n",
    "# This demo is a 'script', i.e. intended to be run step by step in a\n",
    "# Python IDE such as spyder. It is organised in 'cells'. spyder displays these\n",
    "# cells nicely and allows you to run each cell on its own.\n",
    "#\n",
    "# First version: 27th of March 2019\n",
    "# Author: Johannes Mayer\n",
    "#\n",
    "\n",
    "## CCP PETMR Synergistic Image Reconstruction Framework (SIRF).\n",
    "## Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.\n",
    "## Copyright 2015 - 2017 University College London.\n",
    "## Copyright 2015 - 2017 Physikalisch-Technische Bundesanstalt.\n",
    "##\n",
    "## This is software developed for the Collaborative Computational\n",
    "## Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "## (http://www.ccppetmr.ac.uk/).\n",
    "##\n",
    "## Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "##   you may not use this file except in compliance with the License.\n",
    "##   You may obtain a copy of the License at\n",
    "##       http://www.apache.org/licenses/LICENSE-2.0\n",
    "##   Unless required by applicable law or agreed to in writing, software\n",
    "##   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "##   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "##   See the License for the specific language governing permissions and\n",
    "##   limitations under the License.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "__version__ = '0.1.0'\n",
    "\n",
    "# import engine module\n",
    "import pGadgetron as pMR\n",
    "\n",
    "# import further modules\n",
    "import os, numpy, copy\n",
    "%matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% GO TO MR FOLDER\n",
    "os.chdir(pMR.petmr_data_path('mr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this function to norm the \n",
    "def norm_array( arr ):\n",
    "    min_a = abs(arr).min()\n",
    "    max_a = abs(arr).max()\n",
    "    \n",
    "    return (arr - min_a)/(max_a - min_a)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to get warmed up again:\n",
    "Since we deal with undersampled data in this last section, we need to compare it to a reference.\n",
    "So we need to reconstruct the fully sampled dataset we encountered before.\n",
    "\n",
    "This is an ideal opprotunity to test what we learned and employ the `pMR.FullSampledReconstructor` class from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Task: Fully sampled reconstruction\n",
    "\n",
    "__Hint:__ As always: the `Tab` key is your friend and autosuggestion tool!\n",
    "\n",
    "__Please write code that does the following:__\n",
    "- create a variable called `full_acq_data` of type `pMR.AcquisitionData` from the file simulated_MR_2D_cartesian.h5\n",
    "- create a variable called `pp_full_acq_data` and assign it the preprocessed data by calling the function `pMR.preprocess_acquisition_data` on our variable `full_acq_data`\n",
    "- create a variable called `recon` of type `pMR.FullySampledReconstructor()`\n",
    "- call the `set_input` method of `recon` on `pp_full_acq_data` to assign our fully sampled dataset to our reconstructor\n",
    "- call the `process()` method of `recon` without arguments (but don't forget the brackets!)\n",
    "- create a variable called `fs_image` and assign it the output of the `get_output` method of `recon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't look at the solution before you tried! \n",
    "Cells to run:\n",
    "- Skip `#Solution Cell` if you want to see if your code works and run #Validation Cell instead.\n",
    "- If it fails, run `#Solution Cell` instead and then `#Validation Cell` afterwards. Then you are up to date again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Cell\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_acq_data = pMR.AcquisitionData('simulated_MR_2D_cartesian.h5')\n",
    "pp_full_acq_data = pMR.preprocess_acquisition_data( full_acq_data )\n",
    "\n",
    "recon = pMR.FullySampledReconstructor()\n",
    "recon.set_input( pp_full_acq_data )\n",
    "recon.process()\n",
    "fs_image = recon.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VALIDATION CELL\n",
    "fs_image_array = fs_image.as_array()\n",
    "fs_image_array = norm_array(fs_image_array)\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "plt.set_cmap('gray')\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow( abs(fs_image_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('Fully sampled reconstruction')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_fft( k_array ):\n",
    "    image_array = numpy.zeros(k_array.shape, numpy.complex128)\n",
    "    for c in range(num_channels):\n",
    "        image_array[:,c,:] = numpy.fft.fftshift( numpy.fft.ifft2( numpy.fft.ifftshift(k_array[:,c,:])))\n",
    "#     image_array = image_array/image_array.max()    \n",
    "    image_array = numpy.sum( image_array, 1)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING AND PREPROCESSING DATA FOR THIS SET\n",
    "acq_data = pMR.AcquisitionData('simulated_MR_2D_cartesian_Grappa2.h5')\n",
    "preprocessed_data = pMR.preprocess_acquisition_data(acq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the data we loaded sorted? False\n",
      "Is the data we loaded undersampled? 1\n"
     ]
    }
   ],
   "source": [
    "# LET'S GET SOME INFORMATION FROM THE DATA\n",
    "print('Is the data we loaded sorted? %s' % preprocessed_data.is_sorted())\n",
    "print('Is the data we loaded undersampled? %s' % preprocessed_data.is_undersampled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the data we loaded sorted? True\n"
     ]
    }
   ],
   "source": [
    "# OK SO LET'S SORT IT THEN\n",
    "preprocessed_data.sort()\n",
    "print('Is the data we loaded sorted? %s' % preprocessed_data.is_sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of k-space 160x8x256\n"
     ]
    }
   ],
   "source": [
    "#%% RETRIEVE K-SPACE DATA\n",
    "k_array = preprocessed_data.as_array()\n",
    "print('Size of k-space %dx%dx%d' % k_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of k-space 160x8x256\n"
     ]
    }
   ],
   "source": [
    "#%% SELECT VIEW DATA FROM DIFFERENT COILS\n",
    "print('Size of k-space %dx%dx%d' % k_array.shape)\n",
    "\n",
    "num_channels = k_array.shape[1]\n",
    "\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure(1)\n",
    "plt.set_cmap('gray')\n",
    "for c in range(num_channels):\n",
    "    ax = fig.add_subplot(2,4,c+1)\n",
    "    ax.imshow(abs(k_array[:,c,:]), vmin=0, vmax=1)\n",
    "    ax.set_title('Coil '+str(c+1))\n",
    "    ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty similar to what we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we make a FFT of the data we looked at and compare it to our fully sampled image\n",
    "image_array_sos = our_fft( k_array )\n",
    "image_array_sos = norm_array(image_array_sos)\n",
    "\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(abs(image_array_sos), vmin=0, vmax=1)\n",
    "ax.set_title('Undersampled')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(abs(fs_image_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('Fully Sampled')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "Please answer the following question for yourself:\n",
    "- What differences appear between the two reconstructions?\n",
    "- What artifacts appear in the Undersampled reconstruction?\n",
    "- Why is the undersampled reconstruction clinched, but contains the whole image?\n",
    "- We found that our dataset is undersampled. What parts of k-space do you expect to be missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW LET'S LOOK WHICH PARTS ARE SAMPLED AND WHICH ARE LEFT OUT\n",
    "which_ro = preprocessed_data.get_info('kspace_encode_step_1')\n",
    "sampling_mask = numpy.zeros([256,256])\n",
    "\n",
    "for ro in which_ro:\n",
    "    sampling_mask[ro,:] = 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLOT THE SAMPLING MASK    \n",
    "plt.close()\n",
    "fig = plt.figure(1)\n",
    "plt.set_cmap('gray')\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow( sampling_mask, vmin=0, vmax=1)\n",
    "ax.set_title('Sampling pattern of a GRAPPA acquisition')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that $160 = \\frac{256}{2} + 32$.\n",
    "This means the around the center of k-space is densely sampled containing 64 readout lines.\n",
    "The outside of k-space is undersampled by a factor of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workaround: 'zero-fill' the k-space data\n",
    "Since the shape of the data seems to be the problem, let's just change that shape into the one we want.\n",
    "\n",
    "But can we just add datapoints? This will corrupt the data!\n",
    "\n",
    "Actually, a Fourier transform is just a sum weighted by a phase. \n",
    "\n",
    "So it does not mind if we add zeros to it!\n",
    "\n",
    "This means we make a larger array, add our data in the correct spots, and the gaps we fill with zeros. The correct spots are given by our sampling mask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_shape = [sampling_mask.shape[0], num_channels, sampling_mask.shape[1]]\n",
    "zf_k_array = numpy.zeros(k_shape, numpy.complex128)\n",
    "\n",
    "for i in range(k_array.shape[0]):\n",
    "    zf_k_array[which_ro[i],:,:] = k_array[i,:,:]\n",
    "\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "plt.set_cmap('gray')\n",
    "for c in range(num_channels):\n",
    "    ax = fig.add_subplot(2,4,c+1)\n",
    "    ax.imshow(abs(zf_k_array[:,c,:]), vmin=0, vmax=1)\n",
    "    ax.set_title('Coil '+str(c+1))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstruct the zero-filled data and take a look\n",
    "zf_recon = our_fft( zf_k_array)\n",
    "zf_recon = norm_array(zf_recon)\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.imshow(abs(zf_recon), vmin=0, vmax=1)\n",
    "ax.set_title('Zero-filled Undersampled ')\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.imshow(abs(fs_image_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('Fully Sampled ')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: \n",
    "Bummer. Now the shape is correct, however the artifacts are still present. To get rid of these we will need some parallel imaging techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coilmap computation\n",
    "On the topic of parallel imaging, this has something to do with exploiting the spatially varying coil sensitivities.  \n",
    "So we should probably look at them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHICH COILMAPS DO WE GET FROM THIS DATASET?\n",
    "csm = pMR.CoilSensitivityData()\n",
    "csm.smoothness = 40\n",
    "csm.calculate(preprocessed_data)\n",
    "csm_array = numpy.squeeze(csm.as_array(0))\n",
    "\n",
    "csm_array = csm_array.transpose([1,0,2])\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "plt.set_cmap('jet')\n",
    "for c in range(csm_array.shape[1]):\n",
    "    ax = fig.add_subplot(2,4,c+1)\n",
    "    ax.imshow(abs(csm_array[:,c,:]))\n",
    "    ax.set_title('Coil '+str(c+1))\n",
    "    ax.axis('off')\n",
    "plt.set_cmap('gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "Why is it not important in estimating coilmaps, that\n",
    "- we have only a fully sampled  k-space center?\n",
    "- there are artifacts in the reconstruction? Why are they not in the coilmaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT WOULD HAVE HAPPENED IF WE DIDN'T ACQUIRE THE CENTER?\n",
    "\n",
    "zf_k_array[0:2:,:,:] = 0\n",
    "\n",
    "\n",
    "preprocessed_data.fill( zf_k_array )\n",
    "csm.calculate(preprocessed_data)\n",
    "\n",
    "csm_array = numpy.squeeze(csm.as_array(0))\n",
    "\n",
    "csm_array = csm_array.transpose([1,0,2])\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "plt.set_cmap('jet')\n",
    "for c in range(csm_array.shape[1]):\n",
    "    ax = fig.add_subplot(2,4,c+1)\n",
    "    ax.imshow(abs(csm_array[:,c,:]))\n",
    "    ax.set_title('Coil '+str(c+1))\n",
    "    ax.axis('off')\n",
    "plt.set_cmap('gray')\n",
    "\n",
    "# FILL ORIGINAL DAYA WITH CENTER BACK INTO OUR CONTAINER\n",
    "preprocessed_data.fill(k_array)\n",
    "csm.calculate(preprocessed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      " reconstructing...\n"
     ]
    }
   ],
   "source": [
    "# NOW DO A GRAPPA RECONSTRUCTION\n",
    "\n",
    "recon = pMR.CartesianGRAPPAReconstructor()\n",
    "recon.set_input(preprocessed_data)\n",
    "recon.compute_gfactors(False)\n",
    "print('---\\n reconstructing...')\n",
    "\n",
    "recon.process()\n",
    "# for undersampled acquisition data GRAPPA computes Gfactor images\n",
    "# in addition to reconstructed ones\n",
    "grappa_images = recon.get_output()\n",
    "grappa_images_array = grappa_images.as_array()\n",
    "grappa_images_array = norm_array(grappa_images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLOT THE RESULTS\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1,3,1)\n",
    "ax.imshow(abs(zf_recon), vmin=0, vmax=1)\n",
    "ax.set_title('Zero-filled Undersampled ')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(1,3,2)\n",
    "ax.imshow(abs(grappa_images_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('GRAPPA')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(1,3,3)\n",
    "ax.imshow(abs(fs_image_array[0,:,:]), vmin=0, vmax=1)\n",
    "ax.set_title('Fully Sampled')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Well, that was very little code to perform a difficult task! That is because we sent our data off to The Gadgetron and they did all the work.\n",
    "\n",
    "In what respect did a GRAPPA reconstruction:\n",
    "\n",
    " * improve the resulting image?\n",
    " * deterioate the resulting image?\n",
    " * why is there more noise in the GRAPPA reconstruction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREAT! Now we want to develop our own algorithm and be better than the GRAPPA reconstruction!\n",
    "## Urgh, let's rather not because we are so annoyed at how much code we have to write all the time!\n",
    "### Enter: AcquisitionModel\n",
    "\n",
    "We want to capture our entire imaging and reconstruction process in one single object and don't care about data structure. Also we don't want to have to sum over coil channels all the time and take care of zero filling, this is just too much work!  \n",
    "\n",
    "In SIRF there exists something called AcquisitionModel, in the literature also referenced as and Encoding operator $E$, E for encoding.\n",
    "\n",
    "For an image $x$, we want to be able to go __forward__ into k-space\n",
    "$$ E: x \\rightarrow y $$\n",
    "implicitly performing multiplication of the image with the coil sensitivities $C_c$ for each channel $c$ and performing an FFT:\n",
    "\n",
    "$$\n",
    "E x = y_c = \\mathcal{F}( C_c \\cdot x) \n",
    "$$\n",
    "\n",
    "For given k-space data, we want to __backward__ into image space, doing the zero-filling, inverse FFT, and coil combination as one single operation:\n",
    "$$ E^H: y \\rightarrow x $$\n",
    ", implicitly performing everything:  \n",
    "$$\n",
    "E^H y = x =  \\frac{\\sum_c C_c^*\\mathcal{F}^{-1}(y) }{\\sum_c C_c^*C_c}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE GENERATE THE E OPERATOR FROM ABOVE AND ASSIGN OUR COIL SENSITIVITIES\n",
    "E = pMR.AcquisitionModel(preprocessed_data, grappa_images)\n",
    "E.set_coil_sensitivity_maps(csm)\n",
    "\n",
    "# Now we can hop back from k-space to image space in just one line:\n",
    "aq_model_image = E.backward( preprocessed_data )\n",
    "aq_model_image_array = aq_model_image.as_array()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this is not much code any more. Suddenly implementing an iterative algorithm seems feasible\n",
    "### QUESTION\n",
    "BEFORE YOU RUN THE NEXT CELL AND LOOK AT THE PLOT:\n",
    "In the next plot the image stored in `aq_model_image_array` will be shown, i.e. $x = E^H y$.  \n",
    "Based on the discussion what the AcquisitionModel E does, what do you expect the reconstruction to look like?\n",
    "- Is it clinched or is it the correct size?\n",
    "- Does it contain artifacts? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.set_cmap('gray')\n",
    "fig = plt.figure(5)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(aq_model_image_array[0,:,:]))\n",
    "ax.set_title('Result Backward Method of E ')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Well, bummer again, the artifacts are still there!__ Of course, the acquisition model is just a compact version of our above code. We need something smarter to kill them off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Gradient SENSE\n",
    "## Iterative Parallel Imaging Reconstruction\n",
    "\n",
    "In order to employ parallel imagaing, we should look at image reconstruction as an inverse problem.\n",
    "By \"image reconstruction\" we actually mean to achieve the following equality:\n",
    "$$ E x = y $$, or equivalently\n",
    "$$ E^H E x = E^H y$$ \n",
    "where $E$ is the encoding operator $x$ is the true image object and $y$ is the MR raw data we acquired. \n",
    "The task of image reconstruction boils down to optimizing the following function:\n",
    "$$ \\mathcal{C}(x) = \\frac{1}{2} \\bigl{|} \\bigl{|}  E x - y \\bigr{|} \\bigr{|}_2  \\\\\n",
    "\\tilde{x} = \\min_x \\mathcal{C}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to implement Conjugate Gradient Descent SENSE\n",
    "Is that going to be better than a GRAPPA reconstruction? \n",
    "For that we need to write a bit of code:\n",
    "- We already have this encoding operator `E` defined.\n",
    "- Now we need to use it to iteratively optimize our cost function with a conjugate gradient descent optimization.\n",
    "\n",
    "To this end we can study the corresponding [Wikipedia Article](https://en.wikipedia.org/wiki/Conjugate_gradient_method#Description_of_the_problem_addressed_by_conjugate_gradients).\n",
    "\n",
    "This looks like our thang! We don't care too much about maths, but we want the [algorithm](https://en.wikipedia.org/wiki/Conjugate_gradient_method#The_resulting_algorithm).\n",
    "\n",
    "\n",
    "They want to compute x in $Ax = b$, we want to compute x in $E^H E x = E^H y$.  \n",
    "This means we need to translate what it says on Wikipedia:\n",
    "- $A$ = $E^HE$\n",
    "- $b$ = $E y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming task\n",
    "Please write code executing the following task:\n",
    "- define a fuction named `EhE`\n",
    "- it should have one single argument `image`\n",
    "- it should return $E^H( E (image))$  \n",
    "\n",
    "__Hint 1:__ We defined `E` already. Use it's methods `forward` and `backward`. `forward` goes from image space to k-space and `backward` the other way round.  \n",
    "__Hint 2:__ Short reminder on the syntax. The function should look like: \n",
    "```\n",
    "def function_name( arugment_name):\n",
    "    variable = code_that_does_something_with ( argument_name )\n",
    "    return variable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here (this is as much space as you need!)\n",
    "# make sure the name of your function is EhE \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't look at the solution before you tried! \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We define a function to save some work\n",
    "def EhE( image ):\n",
    "    return E.backward( E.forward(image) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to Wikipedia\n",
    "Now we have all the tools we need. Now let's get back to Wikipedia.\n",
    "We want the [algorithm](https://en.wikipedia.org/wiki/Conjugate_gradient_method#The_resulting_algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our images should be the same shape as the GRAPPA outout\n",
    "recon_img =  grappa_images \n",
    "\n",
    "# but we want to start from zero\n",
    "zero_array = recon_img.as_array()\n",
    "zero_array.fill(0)\n",
    "recon_img.fill(zero_array)\n",
    "\n",
    "# now name the variables the same as in the wikipedia article:\n",
    "x = recon_img\n",
    "y = preprocessed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming task: Initialize Iterative Reconstruction\n",
    "Please write code executing the following task:\n",
    "- Initialize a variable `r` with `r` = $b - Ax$ (`r` stands for residual) If you forgot what $b$ and $A$ were in our context scroll back up!\n",
    "- Print the type of `r` using Pythons `type()` function. What type do you expect? Is it an image, or is it acquisition data?\n",
    "- After you wrote these two lines run your cell pressing `Ctrl+Enter`, to get the output of the print statement.\n",
    "- Afterwards, initialize a variable named `rr` with `rr` = $r^\\dagger r$. (`rr` stands for r times r)  \n",
    "__Hint__: No need to access any numpy arrays! Objects of type `sirf.Gadgetron.ImageData` have the method called ` norm()` giving you the square root of the quanitity we are looking for. `rr` is the value of the cost funciton by the way.\n",
    "- Initialize a variable `rr0` with the value of `rr` to store the starting norm of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE IN THIS CELL\n",
    "## Please make sure to name the variables correctly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of r is: <class 'sirf.Gadgetron.ImageData'>\n"
     ]
    }
   ],
   "source": [
    "##### Don't look at the solution before you tried! #############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "# this is our first residual\n",
    "r = E.backward( y ) - EhE(x)\n",
    "\n",
    "# print the type\n",
    "print('The type of r is: ' + str( type(r) ) ) \n",
    "\n",
    "# this is our cost function at the start\n",
    "rr = r.norm() ** 2\n",
    "rr0 = rr\n",
    "\n",
    "# intialize p\n",
    "p = r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we write down the algorithm\n",
    "\n",
    "# how many iterative steps do we want\n",
    "# how low should the cost be\n",
    "num_iter = 10\n",
    "sufficiently_small = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for k = 0: 1.0\n",
      "Cost for k = 1: 0.373820362814\n",
      "Cost for k = 2: 0.149355357173\n",
      "Cost for k = 3: 0.0485647590065\n",
      "Cost for k = 4: 0.0166039420608\n",
      "Cost for k = 5: 0.00700911384402\n",
      "Cost for k = 6: 0.00254856484792\n",
      "Cost for k = 7: 0.00101426448403\n",
      "Cost for k = 8: 0.000599625780264\n",
      "Cost for k = 9: 0.000274158628379\n",
      "Cost for k = 10: 9.29402923914e-05\n"
     ]
    }
   ],
   "source": [
    "print('Cost for k = 0: '  + str( rr/ rr0) )\n",
    "for k in range(num_iter):\n",
    "    \n",
    "    Ap = EhE( p )\n",
    "       \n",
    "    alpha = rr / numpy.sum( (numpy.conj(p.as_array())) * Ap.as_array() ) \n",
    "    \n",
    "    x = x + alpha * p\n",
    "    r = r - alpha * Ap\n",
    "    \n",
    "    beta  = r.norm()**2 / rr\n",
    "    rr = r.norm()**2\n",
    "    \n",
    "    p = r + beta * p\n",
    "    \n",
    "    print('Cost for k = ' +str(k+1) + ': ' + str( rr/ rr0) )\n",
    "    if( rr/rr0 < sufficiently_small ):\n",
    "        print( 'We achieved our desired accuracy. Stopping iterative reconstruction' )\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "recon_arr = norm_array( x.as_array())\n",
    "\n",
    "plt.set_cmap('gray')\n",
    "fig = plt.figure(5)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(abs(recon_arr[0,:,:]))\n",
    "ax.set_title('SENSE RECONSTRUCTION')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 255.5, 255.5, -0.5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's Plot\n",
    "recon_arr = x.as_array()\n",
    "\n",
    "plt.close()\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(2,2,1)\n",
    "ax.imshow(abs(aq_model_image_array[0,:,:]))\n",
    "ax.set_title('UNDERSAMPLED RECONSTRUCTION')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(2,2,2)\n",
    "ax.imshow(abs(grappa_images_array[0,:,:]))\n",
    "ax.set_title('GRAPPA RECONSTRUCTION')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(2,2,3)\n",
    "ax.imshow(abs(recon_arr[0,:,:]))\n",
    "ax.set_title('SENSE RECONSTRUCTION')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = fig.add_subplot(2,2,4)\n",
    "ax.imshow(abs(fs_image_array[0,:,:]))\n",
    "ax.set_title('FULLY SAMPLED RECONSTRUCTION')\n",
    "ax.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you had typed this into your computer in 2001 and written a [paper](https://scholar.google.de/scholar?hl=de&as_sdt=0%2C5&q=Advances+in+sensitivity+encoding+with+arbitrary+k%E2%80%90space+trajectories&btnG=) on it, then 18 years later you had 1000 citations (plus 5992 citations from the [previous one](https://scholar.google.de/scholar?hl=de&as_sdt=0%2C5&q=SENSE%3A+sensitivity+encoding+for+fast+MRI&btnG=)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
