{
 "metadata": {
  "name": "",
  "signature": "sha256:e4827c7559b24b9be40cfd99963896f42b45c11c2bbbd2cd5ae3839a4f2c34d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Initial imports etc\n",
      "import numpy\n",
      "from numpy.linalg import norm\n",
      "%matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.animation as animation\n",
      "import os\n",
      "import sys\n",
      "import shutil\n",
      "# plotting settings\n",
      "plt.ion() # interactive 'on' such that plots appear during loops\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: TkAgg\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Use the 'pet' prefix for all SIRF functions\n",
      "# This is done here to explicitly differentiate between SIRF pet functions and \n",
      "# anything else.\n",
      "import pSTIR as pet\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% First define some handy function definitions\n",
      "# To make subsequent code cleaner, we have a few functions here. You can ignore\n",
      "# ignore them when you first see this demo.\n",
      "# They have (minimal) documentation using Python docstrings such that you \n",
      "# can do for instance \"help(imshow)\"\n",
      "#\n",
      "# First a function to display an image\n",
      "def imshow(image, limits, title=''):\n",
      "    \"\"\"Display an image with a colourbar, returning the plot handle. \n",
      "    \n",
      "    Arguments:\n",
      "    image -- a 2D array of numbers\n",
      "    limits -- colourscale limits as [min,max]. An empty [] uses the full range\n",
      "    title -- a string for the title of the plot (default \"\")\n",
      "    \"\"\"\n",
      "    plt.title(title)\n",
      "    bitmap=plt.imshow(image)\n",
      "    if len(limits)==0:\n",
      "        limits=[image.min(),image.max()]\n",
      "                \n",
      "    plt.clim(limits[0], limits[1])\n",
      "    plt.colorbar(shrink=.6)\n",
      "    plt.axis('off');\n",
      "    return bitmap\n",
      "\n",
      "def make_positive(image_array):\n",
      "    \"\"\"Truncate any negatives in an ndarray to zero.\"\"\"\n",
      "    image_array[image_array<0] = 0;\n",
      "    return image_array;\n",
      "\n",
      "def make_cylindrical_FOV(image):\n",
      "    \"\"\"Truncate a pet image to a cylindrical FOV.\"\"\"\n",
      "    filter = pet.TruncateToCylinderProcessor()\n",
      "    filter.apply(image)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Go to directory with input files\n",
      "# Adapt this path to your situation (or start everything in the relevant directory)\n",
      "os.chdir(pet.petmr_data_path('pet'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Copy files to a working folder and change directory to where these files are.\n",
      "# We do this to avoid cluttering your SIRF files. This way, you can delete \n",
      "# working_folder and start from scratch.\n",
      "shutil.rmtree('working_folder/brain',True)\n",
      "shutil.copytree('brain','working_folder/brain')\n",
      "os.chdir('working_folder/brain')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% OK. finally done with initial set-up...\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Read in images\n",
      "# Here we will read some images provided with the demo using the ImageData class.\n",
      "# These are in Interfile format. Check the main SIRF doc.\n",
      "image = pet.ImageData('emission.hv');\n",
      "mu_map = pet.ImageData('attenuation.hv');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% What is an ImageData?\n",
      "# Images are represented by objects with several methods. The most important method \n",
      "# is as_array() which we'll use below.\n",
      "# Let's see what all the methods are.\n",
      "help(pet.ImageData)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on class ImageData in module sirf.STIR:\n",
        "\n",
        "class ImageData(DataContainer)\n",
        " |  Class for PET image data objects.\n",
        " |  \n",
        " |  ImageData objects contains both geometric data and the actual voxel\n",
        " |  values. You have to use the `as_array` method to get an array with\n",
        " |  the voxel values, and use the `fill` function to change the voxel values.\n",
        " |  \n",
        " |  Method resolution order:\n",
        " |      ImageData\n",
        " |      DataContainer\n",
        " |      abc.ABC\n",
        " |      __builtin__.object\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __del__(self)\n",
        " |      Deallocates this ImageData object.\n",
        " |  \n",
        " |  __init__(self, arg=None)\n",
        " |      Create an ImageData object\n",
        " |      \n",
        " |      Arguments:\n",
        " |      str            : read the object from a file specified by <arg>\n",
        " |                       (the file format has to be support by STIR).\n",
        " |      AcquisitionData: create an object compatible with the scanner data\n",
        " |                       recorded in an AcquisitionData object <arg>.\n",
        " |                       This sets default voxel sizes.\n",
        " |      None           : create an empty ImageData object. Call initialise()\n",
        " |                       method before using it.\n",
        " |  \n",
        " |  add_shape(self, shape, scale)\n",
        " |      Adds a shape to self - see Shape above.\n",
        " |  \n",
        " |  as_array(self)\n",
        " |      Returns 3D Numpy ndarray with values at the voxels.\n",
        " |  \n",
        " |  clone(self)\n",
        " |      Creates a copy of this image.\n",
        " |  \n",
        " |  dimensions(self)\n",
        " |      Returns image dimensions as a tuple (nx, ny, nz).\n",
        " |  \n",
        " |  fill(self, value)\n",
        " |      Sets the voxel-values.\n",
        " |      \n",
        " |      The argument is either 3D Numpy ndarray of values or a scalar to be\n",
        " |      assigned at each voxel. When using an ndarray, the array size has to\n",
        " |      have the same size as an array returned by `as_array`.\n",
        " |  \n",
        " |  get_uniform_copy(self, value=1.0)\n",
        " |      Creates a copy of this image filled with <value>.\n",
        " |  \n",
        " |  initialise(self, arg1, arg2=0, arg3=0, arg4=1, arg5=1, arg6=1, arg7=0, arg8=0, arg9=0)\n",
        " |      Change image size and geometric information\n",
        " |      \n",
        " |      Sets this image size in voxels, voxel sizes in mm and the origin.\n",
        " |      All arguments except the first one are optional.\n",
        " |      Present arguments are either all scalars or all tuples.\n",
        " |      The first tuple argument or three scalar arguments set the image\n",
        " |      sizes in voxels.\n",
        " |      The second tuple argument or three scalar arguments set the voxel\n",
        " |      sizes in mm (if absent, sizes default to (1,1,1)).\n",
        " |      The third tuple argument or three scalar arguments set the origin\n",
        " |      (if absent, defaults to (0,0,0)).\n",
        " |  \n",
        " |  read_from_file(self, filename)\n",
        " |      Read data from file.\n",
        " |      \n",
        " |      Replaces the current content of the object.\n",
        " |  \n",
        " |  same_object(self)\n",
        " |      See DataContainer.same_object().\n",
        " |  \n",
        " |  show(self, im_num=None)\n",
        " |      Displays xy-cross-sections of this image at z selected interactively.\n",
        " |  \n",
        " |  voxel_sizes(self)\n",
        " |      Returns image voxel sizes as a tuple (vx, vy, vz).\n",
        " |  \n",
        " |  write(self, filename)\n",
        " |      Writes self to an Interfile - see STIR documentation for details.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data and other attributes defined here:\n",
        " |  \n",
        " |  __abstractmethods__ = frozenset([])\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from DataContainer:\n",
        " |  \n",
        " |  __add__(self, other)\n",
        " |      Overloads + for data containers.\n",
        " |      \n",
        " |      Returns the sum of the container data with another container \n",
        " |      data viewed as vectors.\n",
        " |      other: DataContainer\n",
        " |  \n",
        " |  __mul__(self, other)\n",
        " |      Overloads * for data containers multiplication by a scalar or another\n",
        " |      data container.\n",
        " |      \n",
        " |      Returns the product self*other if other is a scalar\n",
        " |      or the dot product if it is DataContainer.\n",
        " |      other: DataContainer or a (real or complex) scalar\n",
        " |  \n",
        " |  __rmul__(self, other)\n",
        " |      Overloads * for data containers multiplication by a scalar from\n",
        " |      the left, i.e. computes and returns the product other*self.\n",
        " |      other: a real or complex scalar\n",
        " |  \n",
        " |  __sub__(self, other)\n",
        " |      Overloads - for data containers.\n",
        " |      \n",
        " |      Returns the difference of the container data with another container \n",
        " |      data viewed as vectors.\n",
        " |      other: DataContainer\n",
        " |  \n",
        " |  dot(self, other)\n",
        " |      Returns the dot product of the container data with another container \n",
        " |      data viewed as vectors.\n",
        " |      other: DataContainer\n",
        " |  \n",
        " |  norm(self)\n",
        " |      Returns the 2-norm of the container data viewed as a vector.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors inherited from abc.ABC:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Use as_array to get the underlying array of numbers\n",
      "image_array=image.as_array();\n",
      "# This a standard numpy 3D array with its associated methods.\n",
      "print(image_array.shape)\n",
      "# Whenever we want to do something with the image-values, we have to do it via this array.\n",
      "# Let's print a voxel-value.\n",
      "print(image_array[0,10,20])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(15, 211, 211)\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Manipulate the image data for illustration\n",
      "# Multiply the data with a factor\n",
      "image_array*=0.01;\n",
      "# Stick this new data into the original image object.\n",
      "# (This will not modify the file content, only the variable in memory.)\n",
      "image.fill(image_array);\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Display the middle slice of the image (which is really a 3D volume)\n",
      "# We will use our own imshow function (which was defined above) for brevity.\n",
      "\n",
      "# Get the middle slice number\n",
      "slice_num=image_array.shape[0]/2;\n",
      "# Create a new figure\n",
      "plt.figure();\n",
      "# Display the slice\n",
      "imshow(image_array[slice_num,:,:,], [], 'emission image');\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% OK. Now we will do some PET projections!\n",
      "# SIRF uses AcquisitionModel as the object to do forward and back-projections.\n",
      "# We will create an AcquisitionModel object and then use it to forward project\n",
      "# our image etc\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Create a SIRF acquisition model\n",
      "# We will use the ray-tracing matrix here as our simple PET model.\n",
      "# There is more to the accquisition model, but that's for another demo.\n",
      "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
      "# Ask STIR to use 5 LORs per sinogram-element\n",
      "am.set_num_tangential_LORs(5);\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Specify sinogram dimensions\n",
      "# We need to say what scanner to use, what dimensions etc.\n",
      "# You do this by using existing PET data as a 'template'. \n",
      "# We read a file supplied with the demo as an AcquisitionData object\n",
      "templ = pet.AcquisitionData('template_sinogram.hs');\n",
      "# Now set-up our acquisition model with all information that it needs about the data and image.\n",
      "am.set_up(templ,image); \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% The AcquisitionModel is now ready for use\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Do a forward projection of our image\n",
      "# 'forward projection' is the terminology used in PET to simulate the acquisition.\n",
      "# Input is a SIRF ImageData object (not image_array), output is an AcquisitionData object.\n",
      "acquired_data=am.forward(image)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Check what methods an AcquisitionData object has\n",
      "help(acquired_data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on AcquisitionData in module sirf.STIR object:\n",
        "\n",
        "class AcquisitionData(DataContainer)\n",
        " |  Class for PET acquisition data.\n",
        " |  \n",
        " |  Method resolution order:\n",
        " |      AcquisitionData\n",
        " |      DataContainer\n",
        " |      abc.ABC\n",
        " |      __builtin__.object\n",
        " |  \n",
        " |  Methods defined here:\n",
        " |  \n",
        " |  __del__(self)\n",
        " |  \n",
        " |  __init__(self, src=None, span=1, max_ring_diff=-1, view_mash_factor=1)\n",
        " |      Creates new AcquisitionData object from a file or another\n",
        " |      AcquisitionData object;\n",
        " |      src:  file name (Python str) or AcquisitionData object or scanner name\n",
        " |  \n",
        " |  as_array(self)\n",
        " |      Returns a copy of acquisition data stored in this object as a\n",
        " |      NumPy ndarray of 3 dimensions (in default C ordering of data):\n",
        " |      - number of sinograms\n",
        " |      - number of views\n",
        " |      - number of tangential positions.\n",
        " |  \n",
        " |  clone(self)\n",
        " |      Returns a true copy of this object (not Python handle).\n",
        " |  \n",
        " |  create_uniform_image(self, value=0, xy=None)\n",
        " |      Creates ImageData object containing PET image of dimensions\n",
        " |      and voxel sizes compatible with the scanner geometry stored\n",
        " |      in this AcquisitionData object and assigns a given value\n",
        " |      to all voxels;\n",
        " |      value:  a Python float.\n",
        " |      xy: y and x dimensions tuple\n",
        " |  \n",
        " |  dimensions(self)\n",
        " |      Returns a tuple of the data dimensions:\n",
        " |      - number of sinograms\n",
        " |      - number of views\n",
        " |      - number of tangential positions.\n",
        " |  \n",
        " |  fill(self, value)\n",
        " |      Fills the object with values;\n",
        " |      value:  either NumPy ndarray or another AcquisitionData object\n",
        " |              or Python float.\n",
        " |  \n",
        " |  get_uniform_copy(self, value=0)\n",
        " |      Returns a true copy of this object filled with a given value;\n",
        " |      value:  a Python float.\n",
        " |  \n",
        " |  read_from_file(self, filename)\n",
        " |      Read data from file.\n",
        " |      \n",
        " |      Replaces the current content of the object.\n",
        " |  \n",
        " |  rebin(self, num_segments_to_combine, num_views_to_combine=1, num_tang_poss_to_trim=0, do_normalisation=True, max_in_segment_num_to_process=-1)\n",
        " |  \n",
        " |  same_object(self)\n",
        " |      See DataContainer.same_object().\n",
        " |  \n",
        " |  write(self, filename)\n",
        " |      Writes self to an Interfile - see STIR documentation for details.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Static methods defined here:\n",
        " |  \n",
        " |  get_storage_scheme()\n",
        " |      Returns acquisition data storage scheme.\n",
        " |  \n",
        " |  set_storage_scheme(scheme)\n",
        " |      Sets acquisition data storage scheme.\n",
        " |      \n",
        " |      scheme = 'file' (default):\n",
        " |          all acquisition data generated from now on will be kept in\n",
        " |          scratch files deleted after the user's script terminates\n",
        " |      scheme = 'memory':\n",
        " |          all acquisition data generated from now on will be kept in RAM\n",
        " |          (avoid if data is very large)\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data and other attributes defined here:\n",
        " |  \n",
        " |  __abstractmethods__ = frozenset([])\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Methods inherited from DataContainer:\n",
        " |  \n",
        " |  __add__(self, other)\n",
        " |      Overloads + for data containers.\n",
        " |      \n",
        " |      Returns the sum of the container data with another container \n",
        " |      data viewed as vectors.\n",
        " |      other: DataContainer\n",
        " |  \n",
        " |  __mul__(self, other)\n",
        " |      Overloads * for data containers multiplication by a scalar or another\n",
        " |      data container.\n",
        " |      \n",
        " |      Returns the product self*other if other is a scalar\n",
        " |      or the dot product if it is DataContainer.\n",
        " |      other: DataContainer or a (real or complex) scalar\n",
        " |  \n",
        " |  __rmul__(self, other)\n",
        " |      Overloads * for data containers multiplication by a scalar from\n",
        " |      the left, i.e. computes and returns the product other*self.\n",
        " |      other: a real or complex scalar\n",
        " |  \n",
        " |  __sub__(self, other)\n",
        " |      Overloads - for data containers.\n",
        " |      \n",
        " |      Returns the difference of the container data with another container \n",
        " |      data viewed as vectors.\n",
        " |      other: DataContainer\n",
        " |  \n",
        " |  dot(self, other)\n",
        " |      Returns the dot product of the container data with another container \n",
        " |      data viewed as vectors.\n",
        " |      other: DataContainer\n",
        " |  \n",
        " |  norm(self)\n",
        " |      Returns the 2-norm of the container data viewed as a vector.\n",
        " |  \n",
        " |  ----------------------------------------------------------------------\n",
        " |  Data descriptors inherited from abc.ABC:\n",
        " |  \n",
        " |  __dict__\n",
        " |      dictionary for instance variables (if defined)\n",
        " |  \n",
        " |  __weakref__\n",
        " |      list of weak references to the object (if defined)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Let's get the Python array\n",
      "acquisition_array = acquired_data.as_array()\n",
      "print(acquisition_array.shape)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11, 64, 90)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Display bitmap of the middle sinogram\n",
      "# AcquisitionData are organised by sinograms, so we need to use the first index\n",
      "# of the accquisition_array.\n",
      "plt.figure()\n",
      "slice_num=acquisition_array.shape[0]/2;\n",
      "imshow(acquisition_array[slice_num,:,:,], [], 'Forward projection');\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Display some different 'views' in a movie\n",
      "# See note at start of file about your backend if this doesn't work.\n",
      "bitmaps=[]\n",
      "fig=plt.figure()\n",
      "# views are the second index in the data\n",
      "num_views=acquisition_array.shape[1]\n",
      "# first construct all the plots\n",
      "for view in range(0,num_views,4):\n",
      "    bitmap=plt.imshow(acquisition_array[:,view,:,]);\n",
      "    plt.clim(0,acquisition_array.max())\n",
      "    plt.axis('off');\n",
      "    bitmaps.append([bitmap])\n",
      "# Display as animation\n",
      "ani = animation.ArtistAnimation(fig, bitmaps, interval=100, blit=True, repeat_delay=1000);\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% Let's do a back-projection\n",
      "# Backprojection uses the transpose of the forward-projection matrix to\n",
      "# go from AcquisitionData to an ImageData\n",
      "backprojected = am.backward(acquired_data);\n",
      "# let's display a slice\n",
      "plt.figure()\n",
      "backprojected_array=backprojected.as_array();\n",
      "imshow(backprojected_array[slice_num,:,:],[], 'backprojection');\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%% close all plots\n",
      "plt.close('all')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}